{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UFCStats.queries import DatabaseQuery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Database Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run queries to add db data to pandas dataframes\n",
    "DQ = DatabaseQuery()\n",
    "\n",
    "def query_to_df(query):\n",
    "    df = pd.DataFrame(query.fetchall())\n",
    "    df.columns = query.keys()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query database for fight details\n",
    "fight_cols = ['fight_id', 'event_id', 'weightclass', 'rds_sched', 'rd_ended', 'method', 'bonus', \n",
    "              'fighter_1_id', 'fighter_2_id', 'winner_id', 'tapology_rank', 'deductions']\n",
    "\n",
    "fight_col_str = ', '.join(fight_cols)\n",
    "\n",
    "fight_details = query_to_df(DQ.engine.execute('SELECT ' + fight_col_str + ' FROM fights'))\n",
    "\n",
    "# Query database for round information\n",
    "round_details = query_to_df(DQ.engine.execute('SELECT rd_id, fight_id, rd_num, rd_length FROM rounds'))\n",
    "\n",
    "# Query database for event dates\n",
    "event_dates = query_to_df(DQ.engine.execute('SELECT event_id, event_date FROM events'))\n",
    "\n",
    "# Query database for fighter information\n",
    "fighter_details = query_to_df(DQ.engine.execute('SELECT * FROM fighters'))\n",
    "\n",
    "# Query database for fight statistics by round\n",
    "result_cols = ['rd_id', 'fighter_id', 'kd', 'sig_head_land', 'sig_head_att', 'sig_body_land', \n",
    "               'sig_body_att', 'sig_leg_land', 'sig_leg_att', 'sig_dist_land', 'sig_dist_att',\n",
    "               'sig_clinch_land', 'sig_clinch_att', 'sig_ground_land', 'sig_ground_att', \n",
    "               'total_strike_land', 'total_strike_att', 'takedown_land', 'takedown_att', 'sub_att',\n",
    "               'reversals', 'ctrl_time', 'kd_taken', 'sig_head_taken', 'sig_head_seen', \n",
    "               'sig_body_taken', 'sig_body_seen', 'sig_leg_taken', 'sig_leg_seen', 'sig_dist_taken',\n",
    "               'sig_dist_seen', 'sig_clinch_taken', 'sig_clinch_seen', 'sig_ground_taken', \n",
    "               'sig_ground_seen', 'total_strike_taken', 'total_strike_seen', 'takedown_taken', \n",
    "               'takedown_seen', 'sub_seen', 'reversals_taken', 'ctrl_time_taken']\n",
    "\n",
    "result_col_str = ', '.join(result_cols)\n",
    "\n",
    "stats_by_round = query_to_df(DQ.engine.execute('SELECT ' + result_col_str + ' FROM round_results'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Stats By Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for significant strikes landed and attempted by the fighter and the opponent\n",
    "stats_by_round['total_sig_land'] = stats_by_round['sig_head_land'] + stats_by_round['sig_body_land'] + stats_by_round['sig_leg_land']\n",
    "stats_by_round['total_sig_att'] = stats_by_round['sig_head_att'] + stats_by_round['sig_body_att'] + stats_by_round['sig_leg_att']\n",
    "stats_by_round['total_sig_land_opp'] = stats_by_round['sig_head_taken'] + stats_by_round['sig_body_taken'] + stats_by_round['sig_leg_taken']\n",
    "stats_by_round['total_sig_att_opp'] = stats_by_round['sig_head_seen'] + stats_by_round['sig_body_seen'] + stats_by_round['sig_leg_seen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge round number and round length to fight stats table\n",
    "stats_by_round = stats_by_round.merge(round_details[['rd_id', 'rd_num', 'rd_length']],\n",
    "                                      on='rd_id',\n",
    "                                      how='left'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rounds where control time was not provided on UFCStats.com (NaN)\n",
    "stats_by_round.dropna(subset=['ctrl_time', 'ctrl_time_taken'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for neutral time and control time plus neutral time\n",
    "stats_by_round['ctrl_plus_neutral'] = stats_by_round['rd_length'] - stats_by_round['ctrl_time_taken']\n",
    "stats_by_round['neutral_time'] = stats_by_round['ctrl_plus_neutral'] - stats_by_round['ctrl_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Recency of Fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fight recency table, showing an integer representing how fights into the past (most recent fight = 1)\n",
    "f1_fights = fight_details[['fight_id', 'event_id', 'fighter_1_id']].rename(columns={'fighter_1_id' : 'fighter_id'})\n",
    "f2_fights = fight_details[['fight_id', 'event_id', 'fighter_2_id']].rename(columns={'fighter_2_id' : 'fighter_id'})\n",
    "\n",
    "fight_recency = pd.concat([f1_fights, f2_fights]).reset_index(drop=True)\n",
    "fight_recency['fight_fighter'] = fight_recency['fight_id'] + '-' + fight_recency['fighter_id']\n",
    "fight_recency = fight_recency.merge(event_dates, on='event_id').sort_values(['fighter_id', 'event_date'], ascending=False)\n",
    "\n",
    "fight_recency['recency'] = fight_recency.groupby('fighter_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fight_id column and merge rounds scheduled\n",
    "stats_by_round['fight_id'] = stats_by_round['rd_id'].str.split('-').str[0]\n",
    "stats_by_round= stats_by_round.merge(fight_details[['fight_id', 'rds_sched']], on='fight_id')\n",
    "\n",
    "# Group round stats by fight for later use\n",
    "grouped_by_fight = stats_by_round.groupby(['fighter_id', 'fight_id']).sum().reset_index()\n",
    "\n",
    "# Merge recency information to stats_by_round table and grouped_by_fight table\n",
    "stats_by_round['fight_fighter'] = stats_by_round['fight_id'] + '-' + stats_by_round['fighter_id']\n",
    "stats_by_round = stats_by_round.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                      on='fight_fighter')\n",
    "\n",
    "grouped_by_fight['fight_fighter'] = grouped_by_fight['fight_id'] + '-' + grouped_by_fight['fighter_id']\n",
    "grouped_by_fight = grouped_by_fight.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                          on='fight_fighter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Stats by Fighter and Round of the Fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_stats(stats_by_round, recency_max=1000):\n",
    "    \"\"\"\n",
    "    Group stats by round and fighter, filtered by provided recency.\n",
    "    \"\"\"\n",
    "    stats_by_round = stats_by_round[stats_by_round['recency'] <= recency_max]\n",
    "    grouped_by_round = stats_by_round.groupby(['fighter_id', 'rd_num']).sum().reset_index()\n",
    "    grouped_by_fighter = stats_by_round.groupby('fighter_id').sum().reset_index()\n",
    "    \n",
    "    return grouped_by_round, grouped_by_fighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_round_all, grouped_by_fighter_all = group_stats(stats_by_round.copy())\n",
    "grouped_by_round_past_10, grouped_by_fighter_past_10 = group_stats(stats_by_round.copy(), 10)\n",
    "grouped_by_round_past_5, grouped_by_fighter_past_5 = group_stats(stats_by_round.copy(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Clustering Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Minute of Control/Neutral Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_min_ctrl_neutral(grouped_by_fighter, by_fight=False): \n",
    "    # Calculate stats per minute of control/neutral time\n",
    "    per_ctrl_plus_neutral_cols = ['fighter_id', 'kd', 'kd_taken', 'total_sig_land', 'total_sig_att', 'total_strike_land', 'total_strike_att',\n",
    "                                  'total_sig_land_opp', 'total_strike_taken', 'sub_att', 'ctrl_plus_neutral']\n",
    "    \n",
    "    # New column names\n",
    "    new_cols = ['fighter_id', 'kd_per_min', 'kd_taken_per_min', 'sig_land_per_min', 'sig_att_per_min', 'strike_land_per_min',\n",
    "                'strike_att_per_min', 'sig_absorbed_per_min', 'strike_absorbed_per_min', 'sub_att_per_min', 'ctrl_plus_neutral'\n",
    "               ]\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_ctrl_plus_neutral_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "\n",
    "    per_ctrl_plus_neutral = grouped_by_fighter[per_ctrl_plus_neutral_cols].copy(deep=True)\n",
    "\n",
    "    per_ctrl_plus_neutral.iloc[:, offset:] = per_ctrl_plus_neutral.iloc[:, offset:].div(per_ctrl_plus_neutral['ctrl_plus_neutral'], axis=0).multiply(60, axis=0)\n",
    "\n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_ctrl_plus_neutral.columns = new_cols\n",
    "    \n",
    "    return per_ctrl_plus_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ctrl_plus_neutral_all = per_min_ctrl_neutral(grouped_by_fighter_all)\n",
    "per_ctrl_plus_neutral_past_10 = per_min_ctrl_neutral(grouped_by_fighter_past_10)\n",
    "per_ctrl_plus_neutral_past_5 = per_min_ctrl_neutral(grouped_by_fighter_past_5)\n",
    "\n",
    "per_ctrl_plus_neutral_by_fight = per_min_ctrl_neutral(grouped_by_fight, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Minute of Neutral Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_min_neutral(grouped_by_fighter, by_fight=False):\n",
    "    # Calculate stats per minute of neutral time\n",
    "    per_neutral_cols = ['fighter_id', 'takedown_att', 'takedown_land', 'takedown_taken', 'neutral_time']\n",
    "\n",
    "    # Renaming columns\n",
    "    new_cols = ['fighter_id', 'takedown_att_per_min', 'takedown_land_per_min', 'takedown_absorbed_per_min', 'neutral_time']\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_neutral_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "    \n",
    "    per_neutral = grouped_by_fighter[per_neutral_cols].copy(deep=True)\n",
    "\n",
    "    per_neutral.iloc[:, offset:] = per_neutral.iloc[:, offset:].div(per_neutral['neutral_time'], axis=0).multiply(60, axis=0)\n",
    "\n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_neutral.columns = new_cols\n",
    "    \n",
    "    return per_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_neutral_all = per_min_neutral(grouped_by_fighter_all)\n",
    "per_neutral_past_10 = per_min_neutral(grouped_by_fighter_past_10)\n",
    "per_neutral_past_5 = per_min_neutral(grouped_by_fighter_past_5)\n",
    "\n",
    "per_neutral_by_fight = per_min_neutral(grouped_by_fight, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Minute of Total Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_min_total(grouped_by_fighter, by_fight=False):\n",
    "    # Calculate stats per minute of total time (rd_length)\n",
    "    per_total_time_cols = ['fighter_id', 'ctrl_time', 'ctrl_time_taken', 'rd_length']\n",
    "\n",
    "    # Renaming columns\n",
    "    new_cols = ['fighter_id', 'ctrl_time_per_min', 'ctrl_time_opp_per_min', 'rd_length']\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_total_time_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "    \n",
    "    per_total_time = grouped_by_fighter[per_total_time_cols].copy(deep=True)\n",
    "\n",
    "    per_total_time.iloc[:, offset:] = per_total_time.iloc[:, offset:].div(per_total_time['rd_length'], axis=0).multiply(60, axis=0)\n",
    "    \n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_total_time.columns = new_cols\n",
    "    \n",
    "    return per_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_total_time_all = per_min_total(grouped_by_fighter_all)\n",
    "per_total_time_past_10 = per_min_total(grouped_by_fighter_past_10)\n",
    "per_total_time_past_5 = per_min_total(grouped_by_fighter_past_5)\n",
    "\n",
    "per_total_time_by_fight = per_min_total(grouped_by_fight, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fight Metric Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_ratio_calcs(grouped_by_fighter, by_fight=False):\n",
    "    # Copy the stats by fighter table\n",
    "    metric_ratios = grouped_by_fighter.copy(deep=True)\n",
    "\n",
    "    # Create fight metric ratio columns\n",
    "    metric_ratios['ctrl_time_ratio'] = metric_ratios['ctrl_time'] / metric_ratios['ctrl_time_taken']\n",
    "    metric_ratios['takedown_perc'] = metric_ratios['takedown_land'] / metric_ratios['takedown_att']\n",
    "    metric_ratios['opp_takedown_perc'] = metric_ratios['takedown_taken'] / metric_ratios['takedown_seen']\n",
    "    metric_ratios['leg_strike_rate'] = metric_ratios['sig_leg_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['body_strike_rate'] = metric_ratios['sig_body_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['head_strike_rate'] = metric_ratios['sig_head_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['dist_strike_rate'] = metric_ratios['sig_dist_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['clinch_strike_rate'] = metric_ratios['sig_clinch_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['ground_strike_rate'] = metric_ratios['sig_ground_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['leg_strike_acc'] = metric_ratios['sig_leg_land'] / metric_ratios['sig_leg_att']\n",
    "    metric_ratios['body_strike_acc'] = metric_ratios['sig_body_land'] / metric_ratios['sig_body_att']\n",
    "    metric_ratios['head_strike_acc'] = metric_ratios['sig_head_land'] / metric_ratios['sig_head_att']\n",
    "    metric_ratios['dist_strike_acc'] = metric_ratios['sig_dist_land'] / metric_ratios['sig_dist_att']\n",
    "    metric_ratios['clinch_strike_acc'] = metric_ratios['sig_clinch_land'] / metric_ratios['sig_clinch_att']\n",
    "    metric_ratios['ground_strike_acc'] = metric_ratios['sig_ground_land'] / metric_ratios['sig_ground_att']\n",
    "    metric_ratios['sig_strike_acc'] = metric_ratios['total_sig_land'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['opp_sig_strike_acc'] = metric_ratios['total_sig_land_opp'] / metric_ratios['total_sig_att_opp']\n",
    "    metric_ratios['total_strike_acc'] = metric_ratios['total_strike_land'] / metric_ratios['total_strike_att']\n",
    "    metric_ratios['opp_total_strike_acc'] = metric_ratios['total_strike_taken'] / metric_ratios['total_strike_seen']\n",
    "    metric_ratios['kd_per_sig_strike'] = metric_ratios['kd'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['kd_per_sig_head_strike'] = metric_ratios['kd'] / metric_ratios['sig_head_att']\n",
    "    metric_ratios['opp_kd_per_sig_strike'] = metric_ratios['kd_taken'] / metric_ratios['total_sig_att_opp']\n",
    "    metric_ratios['opp_kd_per_sig_head_strike'] = metric_ratios['kd_taken'] / metric_ratios['sig_head_seen']\n",
    "    \n",
    "    if by_fight:\n",
    "        metric_ratios = metric_ratios[metric_ratio_cols_by_fight]\n",
    "    else:\n",
    "        metric_ratios = metric_ratios[metric_ratio_cols]\n",
    "    \n",
    "    return metric_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the metric ratios table to ratio columns only\n",
    "metric_ratio_cols = ['fighter_id',\n",
    "                     'ctrl_time_ratio',\n",
    "                     'takedown_perc',\n",
    "                     'opp_takedown_perc',\n",
    "                     'leg_strike_rate',\n",
    "                     'body_strike_rate',\n",
    "                     'head_strike_rate',\n",
    "                     'dist_strike_rate',\n",
    "                     'clinch_strike_rate',\n",
    "                     'ground_strike_rate',\n",
    "                     'leg_strike_acc',\n",
    "                     'body_strike_acc',\n",
    "                     'head_strike_acc',\n",
    "                     'dist_strike_acc',\n",
    "                     'clinch_strike_acc',\n",
    "                     'ground_strike_acc',\n",
    "                     'sig_strike_acc',\n",
    "                     'opp_sig_strike_acc',\n",
    "                     'total_strike_acc',\n",
    "                     'opp_total_strike_acc',\n",
    "                     'kd_per_sig_strike',\n",
    "                     'kd_per_sig_head_strike',\n",
    "                     'opp_kd_per_sig_strike',\n",
    "                     'opp_kd_per_sig_head_strike']\n",
    "\n",
    "metric_ratio_cols_by_fight = metric_ratio_cols.copy()\n",
    "metric_ratio_cols_by_fight.insert(1, 'fight_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_ratios_all = metric_ratio_calcs(grouped_by_fighter_all)\n",
    "metric_ratios_past_10 = metric_ratio_calcs(grouped_by_fighter_past_10)\n",
    "metric_ratios_past_5 = metric_ratio_calcs(grouped_by_fighter_past_5)\n",
    "\n",
    "metric_ratios_by_fight = metric_ratio_calcs(grouped_by_fight, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finish Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_metrics(finish_details, grouped_by_fighter, recency_max=1000):\n",
    "    # Group finish details by method and count instances of winner and method combinations\n",
    "    finish_details = finish_details[finish_details['recency'] <= recency_max].copy()\n",
    "    finish_counts = finish_details.groupby(['fighter_id', 'result_method']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "    # Merge sub attempts columns\n",
    "    sub_cols = ['fighter_id', 'sub_att', 'sub_seen']\n",
    "    finish_counts = finish_counts.merge(grouped_by_fighter[sub_cols]) \n",
    "\n",
    "    # Create aggregate columns for win/loss rate calculations\n",
    "    finish_counts['finish_wins'] = finish_counts['win - tko'] + finish_counts['win - sub']\n",
    "    finish_counts['finish_losses'] = finish_counts['loss - tko'] + finish_counts['loss - sub']\n",
    "    finish_counts['num_fights'] = finish_counts.iloc[:, 1:8].sum(axis=1)\n",
    "    finish_counts['num_wins'] = finish_counts['win - decision'] + finish_counts['win - sub'] + finish_counts['win - tko']\n",
    "    finish_counts['num_losses'] = finish_counts['loss - decision'] + finish_counts['loss - sub'] + finish_counts['loss - tko']\n",
    "\n",
    "    # Calculate LOSS rates by different methods, both in terms of versus total fights and total wins\n",
    "    finish_counts['tko_win_per_fight'] = finish_counts['win - tko'] / finish_counts['num_fights']\n",
    "    finish_counts['sub_win_per_fight'] = finish_counts['win - sub'] / finish_counts['num_fights']\n",
    "    finish_counts['dec_win_per_fight'] = finish_counts['win - decision'] / finish_counts['num_fights']\n",
    "    finish_counts['tko_win_per_win'] = finish_counts['win - tko'] / finish_counts['num_wins']\n",
    "    finish_counts['sub_win_per_win'] = finish_counts['win - sub'] / finish_counts['num_wins']\n",
    "    finish_counts['dec_win_per_win'] = finish_counts['win - decision'] / finish_counts['num_wins']\n",
    "\n",
    "    # Calculate LOSS rates by different methods, both in terms of versus total fights and total wins\n",
    "    finish_counts['tko_loss_per_fight'] = finish_counts['loss - tko'] / finish_counts['num_fights']\n",
    "    finish_counts['sub_loss_per_fight'] = finish_counts['loss - sub'] / finish_counts['num_fights']\n",
    "    finish_counts['dec_loss_per_fight'] = finish_counts['loss - decision'] / finish_counts['num_fights']\n",
    "    finish_counts['tko_loss_per_loss'] = finish_counts['loss - tko'] / finish_counts['num_losses']\n",
    "    finish_counts['sub_loss_per_loss'] = finish_counts['loss - sub'] / finish_counts['num_losses']\n",
    "    finish_counts['dec_loss_per_loss'] = finish_counts['loss - decision'] / finish_counts['num_losses']\n",
    "\n",
    "    # Calculate submission success rate for fighter and opponent  (DOESN'T CALC PROPERLY)\n",
    "    #finish_counts['sub_success_rate'] = finish_counts['win - sub'] / finish_counts['sub_att']\n",
    "    #finish_counts['opp_sub_success_rate'] = finish_counts['loss - sub'] / finish_counts['sub_seen']\n",
    "\n",
    "    # Calculate total finish rate and opponent finish rate\n",
    "    finish_counts['finish_rate'] = finish_counts['finish_wins'] / finish_counts['num_fights']\n",
    "    finish_counts['opp_finish_rate'] = finish_counts['finish_losses'] / finish_counts['num_fights']\n",
    "\n",
    "    # Filter to final columns\n",
    "    final_finish_cols = ['fighter_id', 'num_fights', 'tko_win_per_fight', 'sub_win_per_fight', 'dec_win_per_fight',\n",
    "                         'tko_win_per_win', 'sub_win_per_win', 'dec_win_per_win', 'tko_loss_per_fight',\n",
    "                         'sub_loss_per_fight', 'dec_loss_per_fight', 'tko_loss_per_loss', 'sub_loss_per_loss',\n",
    "                         'dec_loss_per_loss', 'finish_rate',\n",
    "                         'opp_finish_rate'\n",
    "                        ]\n",
    "\n",
    "    finish_counts = finish_counts[final_finish_cols]\n",
    "    \n",
    "    return finish_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust fight detail table such that each row represents a fighter's performance in a single fight\n",
    "finish_details_f1 = fight_details[['fight_id', 'method', 'fighter_1_id', 'winner_id']].copy()\n",
    "finish_details_f2 = fight_details[['fight_id', 'method', 'fighter_2_id', 'winner_id']].copy()\n",
    "\n",
    "finish_details_f1.columns = ['fight_id', 'method', 'fighter_id', 'winner_id']\n",
    "finish_details_f2.columns = ['fight_id', 'method', 'fighter_id', 'winner_id']\n",
    "\n",
    "finish_details = pd.concat([finish_details_f1, finish_details_f2]).sort_values('fight_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the method column\n",
    "method_dict = {'Decision - Unanimous' : 'decision',\n",
    "               'Decision - Split' : 'decision',\n",
    "               'Decision - Majority' : 'decision',\n",
    "               'KO/TKO' : 'tko',\n",
    "               'TKO - Doctor\\'s Stoppage' : 'tko',\n",
    "               'Could Not Continue\t' : 'exclude',\n",
    "               'Could Not Continue' : 'exclude',\n",
    "               'Overturned' : 'exclude',\n",
    "               'Other' : 'exclude',\n",
    "               'DQ' : 'exclude',\n",
    "               'Submission' : 'sub'\n",
    "              }\n",
    "\n",
    "finish_details.replace({'method': method_dict}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results column to reflect win/loss/draw and method\n",
    "finish_details['result'] = np.where(finish_details['fighter_id']==finish_details['winner_id'], 'win',\n",
    "                                    np.where(finish_details['winner_id']=='Draw', 'draw',\n",
    "                                             np.where(finish_details['winner_id']=='NC', 'no contest', 'loss')                                                    \n",
    "                                            )\n",
    "                                   )\n",
    "\n",
    "finish_details_by_fight = finish_details.copy(deep=True)\n",
    "\n",
    "finish_details = finish_details[(~finish_details['result'].isin(['no contest'])) &\n",
    "                                (~finish_details['method'].isin(['exclude']))\n",
    "                               ]\n",
    "\n",
    "finish_details['result_method'] = finish_details['result'] + ' - ' + finish_details['method']\n",
    "finish_details_by_fight['result_method']=np.where(finish_details_by_fight['result']=='no contest', 'no contest',\n",
    "                                                  finish_details_by_fight['result'] + ' - ' + finish_details_by_fight['method']\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge recency information to finish_details table\n",
    "finish_details['fight_fighter'] = finish_details['fight_id'] + '-' + finish_details['fighter_id']\n",
    "finish_details = finish_details.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                      on='fight_fighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_counts_all = finish_metrics(finish_details.copy(), grouped_by_fighter_all)\n",
    "finish_counts_past_10 = finish_metrics(finish_details.copy(), grouped_by_fighter_past_10, 10)\n",
    "finish_counts_past_5 = finish_metrics(finish_details.copy(), grouped_by_fighter_past_5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create finish table by fight\n",
    "finish_by_fight = finish_details_by_fight.pivot_table(index=['fight_id', 'fighter_id'], columns='result_method', values='result', aggfunc='count').reset_index()\n",
    "finish_by_fight.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control and Strike Pacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag rounds as early or late\n",
    "stats_by_round['early_late'] = np.where(stats_by_round['rds_sched']=='3', np.where(stats_by_round['rd_num']<=2, 'early', 'late'),\n",
    "                                        np.where(stats_by_round['rd_num']<=3, 'early', 'late')\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish columns for pace calculations\n",
    "pace_cols = ['fighter_id', 'early_late', 'rd_length', 'ctrl_time', 'ctrl_time_taken', 'total_sig_land', 'total_sig_land_opp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pace_calcs(stats_by_round, recency_max=1000):\n",
    "    \n",
    "    stats_by_round = stats_by_round[stats_by_round['recency'] <= recency_max]\n",
    "    pace_metrics = stats_by_round[pace_cols].groupby(['fighter_id', 'early_late']).sum().reset_index()\n",
    "    \n",
    "    # Split into two tables, early and late rounds\n",
    "    pace_metrics = pace_metrics.sort_values(['early_late', 'fighter_id'])\n",
    "    early = pace_metrics[pace_metrics['early_late']=='early'].reset_index(drop=True)\n",
    "    late = pace_metrics[pace_metrics['early_late']=='late'].reset_index(drop=True)\n",
    "\n",
    "    # Rename columns\n",
    "    early.columns = ['fighter_id', 'early_late', 'rd_length_early', 'ctrl_time_early', 'ctrl_time_taken_early', 'total_sig_land_early', 'total_sig_land_opp_early']\n",
    "    late.columns = ['fighter_id', 'early_late', 'rd_length_late', 'ctrl_time_late', 'ctrl_time_taken_late', 'total_sig_land_late', 'total_sig_land_opp_late']\n",
    "\n",
    "    # Recombine early and late metrics\n",
    "    pace_metrics = late.merge(early, on='fighter_id')\n",
    "\n",
    "    # Calculate pacing metrics for control and strike rates in early vs late rounds\n",
    "    pace_metrics['control_rate_early'] = pace_metrics['ctrl_time_early'] / pace_metrics['rd_length_early']\n",
    "    pace_metrics['control_rate_late'] = pace_metrics['ctrl_time_late'] / pace_metrics['rd_length_late']\n",
    "    pace_metrics['control_rate_late_vs_early'] = pace_metrics['control_rate_late'] / pace_metrics['control_rate_early']\n",
    "    pace_metrics['sig_strike_rate_early'] = pace_metrics['total_sig_land_early'] / pace_metrics['rd_length_early']\n",
    "    pace_metrics['sig_strike_rate_late'] = pace_metrics['total_sig_land_late'] / pace_metrics['rd_length_late']\n",
    "    pace_metrics['sig_strike_rate_late_vs_early'] = pace_metrics['sig_strike_rate_late'] / pace_metrics['sig_strike_rate_early']\n",
    "\n",
    "    # Filter to the final table of pace metrics\n",
    "    final_pace_cols = ['fighter_id', 'control_rate_late_vs_early', 'sig_strike_rate_late_vs_early']\n",
    "    pace_metrics = pace_metrics[final_pace_cols]\n",
    "    \n",
    "    return pace_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pace_metrics_all = pace_calcs(stats_by_round.copy())\n",
    "pace_metrics_past_10 = pace_calcs(stats_by_round.copy(), 10)\n",
    "pace_metrics_past_5 = pace_calcs(stats_by_round.copy(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metrics(finish_counts, per_ctrl_plus_neutral, per_neutral, per_total_time, metric_ratios, pace_metrics=None, by_fight=False):\n",
    "    \"\"\"\n",
    "    Merge all fighter metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    if by_fight:\n",
    "        merge_col = ['fighter_id',  'fight_id']\n",
    "    else:\n",
    "        merge_col = 'fighter_id'\n",
    "    \n",
    "    merged_metrics = finish_counts.copy()\n",
    "    merged_metrics = merged_metrics.merge(per_ctrl_plus_neutral.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(per_neutral.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(per_total_time.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(metric_ratios, on=merge_col, how='left')\n",
    "    \n",
    "    if by_fight==False:\n",
    "        merged_metrics = merged_metrics.merge(pace_metrics, on=merge_col, how='left')\n",
    "    \n",
    "    return merged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics_all = merge_metrics(finish_counts_all, per_ctrl_plus_neutral_all, per_neutral_all, \n",
    "                                   per_total_time_all, metric_ratios_all, pace_metrics_all)\n",
    "\n",
    "merged_metrics_past_10 = merge_metrics(finish_counts_past_10, per_ctrl_plus_neutral_past_10, per_neutral_past_10, \n",
    "                                       per_total_time_past_10, metric_ratios_past_10, pace_metrics_past_10)\n",
    "\n",
    "merged_metrics_past_5 = merge_metrics(finish_counts_past_5, per_ctrl_plus_neutral_past_5, per_neutral_past_5, \n",
    "                                      per_total_time_past_5, metric_ratios_past_5, pace_metrics_past_5)\n",
    "\n",
    "merged_metrics_by_fight = merge_metrics(finish_by_fight, per_ctrl_plus_neutral_by_fight, per_neutral_by_fight, \n",
    "                                        per_total_time_by_fight, metric_ratios_by_fight, by_fight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Merged Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_metrics(merged_metrics):\n",
    "    \"\"\"\n",
    "    Replace nulls and infinities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace NaN with zero\n",
    "    merged_metrics = merged_metrics.fillna(0)\n",
    "    \n",
    "    # Replace infinity with zero\n",
    "    merged_metrics = merged_metrics.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    return merged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all fight metrics (nan, infinity)\n",
    "merged_metrics_all = clean_up_metrics(merged_metrics_all)\n",
    "merged_metrics_past_10 = clean_up_metrics(merged_metrics_past_10)\n",
    "merged_metrics_past_5 = clean_up_metrics(merged_metrics_past_5)\n",
    "merged_metrics_by_fight = clean_up_metrics(merged_metrics_by_fight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import Scaler, PCA, and K-Means Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import K-Means model\n",
    "with open('nf_km_10.pickle', 'rb') as read_file:\n",
    "    km = pickle.load(read_file)\n",
    "    \n",
    "# Import PCA\n",
    "with open('nf_pca_fighter_style.pickle', 'rb') as read_file:\n",
    "    pca = pickle.load(read_file)\n",
    "    \n",
    "# Import Standard Scaler\n",
    "with open('nf_standard_scaler_fighter_style.pickle', 'rb') as read_file:\n",
    "    st_scale = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Filter and Transform Data for Clustering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_filter_and_transform(fight_metrics):\n",
    "    \"\"\"\n",
    "    Filter for clustering columns and transform using PCA used in initial cluster formation.\n",
    "    \"\"\"\n",
    "    \n",
    "    fight_metrics = fight_metrics[cluster_cols].copy()\n",
    "    fight_metrics_st = st_scale.transform(fight_metrics)\n",
    "    fight_metrics_pca = pca.transform(fight_metrics_st)\n",
    "    \n",
    "    return fight_metrics_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cols = ['head_strike_rate', 'dist_strike_rate', 'sig_att_per_min',\n",
    "                'kd_per_sig_strike', 'sig_strike_acc', 'total_strike_acc',\n",
    "                'opp_kd_per_sig_strike', 'opp_sig_strike_acc', 'sig_absorbed_per_min',\n",
    "                'takedown_land_per_min', 'ctrl_time_per_min', 'sub_att_per_min',\n",
    "                'takedown_absorbed_per_min', 'opp_takedown_perc'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all = scale_filter_and_transform(merged_metrics_all)\n",
    "pca_past_5 = scale_filter_and_transform(merged_metrics_past_5)\n",
    "pca_past_10 = scale_filter_and_transform(merged_metrics_past_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Breakdown by Fighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_breakdown(cluster_data_pca):\n",
    "    \"\"\"\n",
    "    For given PCA data, return a cluster percentage breakdown for each fighter.\n",
    "    \"\"\"\n",
    "    # Calculate Euclidean distance from fighters to each cluster\n",
    "    nodes_to_centroids = distance.cdist(cluster_data_pca, centroids, 'euclidean')\n",
    "    \n",
    "    # Set up dataframe of distances to cluster centroids\n",
    "    nodes_to_centroids_df = pd.DataFrame(nodes_to_centroids, columns=breakdown_cols)\n",
    "\n",
    "    # Convert distances to \"similiarity scores\"\n",
    "    nodes_to_centroids_df['max_distance'] = nodes_to_centroids_df.max(axis=1)\n",
    "    nodes_to_centroids_df = nodes_to_centroids_df.div(nodes_to_centroids_df['max_distance'], axis=0)\n",
    "    nodes_to_centroids_df = 1 - nodes_to_centroids_df\n",
    "\n",
    "    # Convert similarity scores to percentages for each cluster\n",
    "    nodes_to_centroids_df['sum'] = nodes_to_centroids_df.sum(axis=1)\n",
    "    nodes_to_centroids_df = nodes_to_centroids_df.div(nodes_to_centroids_df['sum'], axis=0)\n",
    "\n",
    "    # Eliminate unnecessary columns, calculate dominant cluster\n",
    "    cluster_breakdown = nodes_to_centroids_df[breakdown_cols]\n",
    "    cluster_breakdown['max_percentage'] = cluster_breakdown.max(axis=1)\n",
    "    cluster_breakdown['top_cluster'] = km.predict(cluster_data_pca)\n",
    "    \n",
    "    return cluster_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull centroid positions from K-Means model\n",
    "centroids = km.cluster_centers_\n",
    "\n",
    "# Establish columns for cluster breakdown dataframe\n",
    "breakdown_cols = ['Cluster 0',\n",
    "                  'Cluster 1',\n",
    "                  'Cluster 2',\n",
    "                  'Cluster 3',\n",
    "                  'Cluster 4',\n",
    "                  'Cluster 5',\n",
    "                  'Cluster 6',\n",
    "                  'Cluster 7',\n",
    "                  'Cluster 8',\n",
    "                  'Cluster 9',\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster breakdowns\n",
    "cluster_breakdown_all = cluster_breakdown(pca_all)\n",
    "cluster_breakdown_past_10 = cluster_breakdown(pca_past_10)\n",
    "cluster_breakdown_past_5 = cluster_breakdown(pca_past_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_with_tag(data_list, tag_list):\n",
    "    \n",
    "    df = data_list[0].copy()\n",
    "    df['past_fights'] = tag_list[0]\n",
    "    \n",
    "    for i in range(1, len(data_list)):\n",
    "        df_2 = data_list[i].copy()\n",
    "        df_2['past_fights'] = tag_list[i]\n",
    "        df = pd.concat([df, df_2]).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Fight Metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack and tag fight metrics\n",
    "fighter_metrics_tableau = stack_with_tag([merged_metrics_all, merged_metrics_past_10, merged_metrics_past_5],\n",
    "                                         ['All', 'Past 10', 'Past 5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Cluster Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack and tag cluster breakdowns\n",
    "cluster_breakdown_all['fighter_id'] = merged_metrics_all['fighter_id']\n",
    "cluster_breakdown_past_10['fighter_id'] = merged_metrics_past_10['fighter_id']\n",
    "cluster_breakdown_past_5['fighter_id'] = merged_metrics_past_5['fighter_id']\n",
    "\n",
    "cluster_breakdown_stacked = stack_with_tag([cluster_breakdown_all, cluster_breakdown_past_10, cluster_breakdown_past_5],\n",
    "                                           ['All', 'Past 10', 'Past 5'])\n",
    "\n",
    "# Melt table\n",
    "cluster_breakdown_tableau = cluster_breakdown_stacked[['fighter_id', 'past_fights']  + breakdown_cols].melt(id_vars=['fighter_id', 'past_fights'], \n",
    "                                                                                                            var_name='cluster',\n",
    "                                                                                                            value_name='percentage')\n",
    "# Save copy for later\n",
    "cluster_breakdown = cluster_breakdown_tableau.copy()\n",
    "\n",
    "# Map cluster values to cluster names:\n",
    "cluster_map = {'Cluster 0' : 'High Risk Sub Artist',\n",
    "               'Cluster 1' : 'Patient Power Puncher',\n",
    "               'Cluster 2' : 'Stick and Move',\n",
    "               'Cluster 3' : 'Pressure Wrestler',\n",
    "               'Cluster 4' : 'Head Hunting Wrestler',\n",
    "               'Cluster 5' : 'Glass Cannon',\n",
    "               'Cluster 6' : 'Stand and Bang',\n",
    "               'Cluster 7' : 'Grind It Out',\n",
    "               'Cluster 8' : 'Chinny Grappler',\n",
    "               'Cluster 9' : 'Tactician'\n",
    "              }\n",
    "\n",
    "cluster_breakdown_tableau['f1_cluster'] = cluster_breakdown_tableau['cluster'].map(cluster_map)\n",
    "cluster_breakdown_tableau['cluster'] = cluster_breakdown_tableau['cluster'].map(cluster_map)\n",
    "cluster_breakdown['cluster'] = cluster_breakdown['cluster'].map(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab top clusters for each fighter \n",
    "top_clusters = cluster_breakdown_all[['fighter_id', 'top_cluster']]\n",
    "top_clusters_past_10 = cluster_breakdown_past_10[['fighter_id', 'top_cluster']]\n",
    "top_clusters_past_5 = cluster_breakdown_past_5[['fighter_id', 'top_cluster']]\n",
    "\n",
    "# Map top clusters to cluster names\n",
    "cluster_map_int = {0 : 'High Risk Sub Artist',\n",
    "                   1 : 'Patient Power Puncher',\n",
    "                   2 : 'Stick and Move',\n",
    "                   3 : 'Pressure Wrestler',\n",
    "                   4 : 'Head Hunting Wrestler',\n",
    "                   5 : 'Glass Cannon',\n",
    "                   6 : 'Stand and Bang',\n",
    "                   7 : 'Grind It Out', \n",
    "                   8 : 'Chinny Grappler',\n",
    "                   9 : 'Tactician',\n",
    "                  }\n",
    "\n",
    "top_clusters['top_cluster'] = top_clusters['top_cluster'].map(cluster_map_int)\n",
    "top_clusters_past_10['top_cluster'] = top_clusters_past_10['top_cluster'].map(cluster_map_int)\n",
    "top_clusters_past_5['top_cluster'] = top_clusters_past_5['top_cluster'].map(cluster_map_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with fighter ID's\n",
    "style_matchups = fight_details[['fighter_1_id', 'fighter_2_id', 'winner_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add loser ID\n",
    "style_matchups['loser_id'] = np.where(style_matchups['winner_id']==style_matchups['fighter_1_id'],\n",
    "                                      style_matchups['fighter_2_id'], style_matchups['fighter_1_id'])\n",
    "\n",
    "# Merge number of fights and top clusters for winner and loser ID's\n",
    "style_matchups = style_matchups.merge(merged_metrics_all[['fighter_id', 'num_fights']], left_on='winner_id', right_on='fighter_id')\n",
    "style_matchups = style_matchups.merge(merged_metrics_all[['fighter_id', 'num_fights']], left_on='loser_id', right_on='fighter_id', suffixes=['_winner', '_loser'])\n",
    "\n",
    "style_matchups = style_matchups.merge(top_clusters, left_on='winner_id', right_on='fighter_id')\n",
    "style_matchups = style_matchups.merge(top_clusters, left_on='loser_id', right_on='fighter_id', suffixes=['_winner', '_loser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_matchups = style_matchups[(style_matchups['num_fights_winner']>=10) & (style_matchups['num_fights_loser']>=10)][['top_cluster_winner', 'top_cluster_loser']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by winner and loser ID's to determine which clusters win over others in their matchups\n",
    "winners = style_matchups.groupby(['top_cluster_winner', 'top_cluster_loser']).size().unstack(fill_value=0)\n",
    "losers = style_matchups.groupby(['top_cluster_loser', 'top_cluster_winner']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate win percentage by cluster matchup\n",
    "win_percentage = winners / (winners + losers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up win percentage, rename columns, and map to cluster labels\n",
    "win_percentage = win_percentage.reset_index().melt(id_vars='top_cluster_winner')\n",
    "win_percentage.columns = ['f1_cluster', 'f2_cluster', 'win_percentage']\n",
    "\n",
    "#win_percentage['f1_cluster'] = win_percentage['f1_cluster'].map(cluster_map)\n",
    "#win_percentage['f2_cluster'] = win_percentage['f2_cluster'].map(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_breakdown_tableau = cluster_breakdown_tableau.merge(win_percentage, on='f1_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_breakdown_tableau = cluster_breakdown_tableau.merge(cluster_breakdown[['fighter_id', 'past_fights', 'cluster', 'percentage']],\n",
    "                                                            left_on=['fighter_id', 'past_fights', 'f2_cluster'], \n",
    "                                                            right_on=['fighter_id', 'past_fights', 'cluster'],\n",
    "                                                            suffixes=['','_f2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_breakdown_tableau.drop(columns=['cluster_f2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Fighter Details*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fighter detail table\n",
    "fighter_cols = ['fighter_id', 'first_name', 'last_name', 'nickname', 'gender', 'reach', 'height', \n",
    "                'stance', 'wins', 'losses', 'draws', 'belt', 'last_fight_date', 'latest_weight_class']\n",
    "\n",
    "fighter_details_tableau = fighter_details[fighter_cols]\n",
    "fighter_details_tableau['full_name'] = np.where(fighter_details_tableau['first_name'].isnull(),\n",
    "                                                fighter_details_tableau['last_name'],\n",
    "                                                fighter_details_tableau['first_name'] + ' ' + fighter_details_tableau['last_name']\n",
    "                                               )\n",
    "\n",
    "# Included flipped name (last first) for merging with fighter rankings later\n",
    "fighter_details_tableau['full_name_flipped'] = np.where(fighter_details_tableau['first_name'].isnull(),\n",
    "                                                        fighter_details_tableau['last_name'],\n",
    "                                                        fighter_details_tableau['last_name'] + ' ' + fighter_details_tableau['first_name']\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge top cluster detail (all, past 5, past 10) and set column names\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters, on='fighter_id')\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters_past_10, on='fighter_id', suffixes=('_all', '_past_10'))\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters_past_10, on='fighter_id')\n",
    "fighter_details_tableau = fighter_details_tableau.rename(columns={'top_cluster' : 'top_cluster_past_5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Fight Details*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge fight details to the fight recency table\n",
    "fight_detail_cols = ['fight_id', 'fighter_1_id', 'fighter_2_id', 'winner_id', 'weightclass', 'rds_sched', 'rd_ended', 'method', 'bonus']\n",
    "\n",
    "fight_details_tableau = fight_recency.merge(fight_details[fight_detail_cols], on='fight_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine opponent fighter_id\n",
    "fight_details_tableau['opponent_id'] = np.where(fight_details_tableau['fighter_id']==fight_details_tableau['fighter_1_id'], \n",
    "                                                fight_details_tableau['fighter_2_id'], fight_details_tableau['fighter_1_id'])\n",
    "\n",
    "# Add opponent full name to the fight details table\n",
    "fight_details_tableau = fight_details_tableau.merge(fighter_details_tableau[['fighter_id', 'full_name', 'full_name_flipped']],\n",
    "                                                    left_on='opponent_id', right_on='fighter_id', suffixes=('', '_y'))\n",
    "\n",
    "fight_details_tableau.rename(columns={'full_name' : 'opponent_name',\n",
    "                                      'full_name_flipped' : 'opponent_name_flipped'\n",
    "                                     }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import rankings snapshots\n",
    "with open('rankings_snapshots.pickle', 'rb') as read_file:\n",
    "    snapshots = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime in rankings snapshots and fight detail tables, sort ascending\n",
    "fight_details_tableau['event_date'] = pd.to_datetime(fight_details_tableau['event_date'], format='%Y-%m-%d')\n",
    "fight_details_tableau = fight_details_tableau.sort_values('event_date')\n",
    "\n",
    "snapshots['date'] = pd.to_datetime(snapshots['date'], format='%m/%d/%Y')\n",
    "snapshots = snapshots.sort_values(['date', 'rank'])\n",
    "\n",
    "# Drop duplicates of event date and fighter name (keep highest ranking)\n",
    "snapshot_no_dups = snapshots.drop_duplicates(subset=['date', 'fighter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace fighter names to match rankings website\n",
    "name_replace = {'Aleksei Oleinik' : 'Alexey Oleynik',\n",
    "                'BJ Penn' : 'B.J. Penn',\n",
    "                'Benson Henderson' : 'Ben Henderson',\n",
    "                'C.B. Dollaway' : 'CB Dollaway',\n",
    "                'Constantinos Philippou' : 'Costas Philippou',\n",
    "                'Dooho Choi' : 'Doo Ho Choi',\n",
    "                'Georges St-Pierre' : 'Georges St. Pierre',\n",
    "                'JJ Aldrich' : 'J.J. Aldrich',\n",
    "                'Jacare Souza' : 'Ronaldo Souza',\n",
    "                'Jimy Hettes' : 'Jim Hettes',\n",
    "                'Joe Duffy' : 'Joseph Duffy',\n",
    "                'Jose Quinonez' : 'Jose Alberto Quinonez',\n",
    "                'Kai Kara-France' : 'Kai Kara France',\n",
    "                'Khalil Rountree Jr.' : 'Khalil Rountree',\n",
    "                'Luis Henrique' : 'Luis Henrique Barbosa de Oliveira',\n",
    "                'Manvel Gamburyan' : 'Manny Gamburyan',\n",
    "                'Matthew Riddle' : 'Matt Riddle',\n",
    "                'Mike Brown' : 'Mike Thomas Brown',\n",
    "                'Ovince Saint Preux' : 'Ovince St. Preux',\n",
    "                'Renato Moicano' : 'Renato Carneiro',\n",
    "                'Rob Emerson' : 'Robert Emerson',\n",
    "                'Robert Peralta' : 'Robbie Peralta',\n",
    "                'Rogerio Nogueira' : 'Antonio Rogerio Nogueira',\n",
    "                'Rony Jason' : 'Rony Mariano Bezerra',\n",
    "                'Serghei Spivac' : 'Sergey Spivak',\n",
    "                'SeungWoo Choi' : 'Seung Woo Choi',\n",
    "                'TJ Dillashaw' : 'T.J. Dillashaw',\n",
    "                'TJ Grant' : 'T.J. Grant',\n",
    "                'TJ Waldburger' : 'T.J. Waldburger',\n",
    "                'Khaos Williams' : 'Kalinn Williams'\n",
    "               }\n",
    "\n",
    "# Remap incorrect names using dictionary\n",
    "fight_details_tableau['opponent_name_clean'] = fight_details_tableau['opponent_name']\n",
    "fight_details_tableau['opponent_name_flipped_clean'] = fight_details_tableau['opponent_name_flipped']\n",
    "\n",
    "fight_details_tableau['opponent_name_clean'] = fight_details_tableau['opponent_name_clean'].replace(name_replace)\n",
    "fight_details_tableau['opponent_name_flipped_clean'] = fight_details_tableau['opponent_name_flipped_clean'].replace(name_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean columns for merging (remove apostrophes, all lowercase, strip blanks)\n",
    "def clean_column(df, col):\n",
    "    \"\"\"\n",
    "    Replace apostrophes with blanks, convert to lowercase, and strip any blanks.\n",
    "    \"\"\"\n",
    "    df[col] = df[col].replace({'\\'': ''}, regex=True)\n",
    "    df[col] = df[col].str.lower().str.strip()\n",
    "    \n",
    "clean_column(fight_details_tableau, 'opponent_name_clean')\n",
    "clean_column(fight_details_tableau, 'opponent_name_flipped_clean')\n",
    "clean_column(snapshot_no_dups, 'fighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rankings data based on the latest snapshot (merge \"as of\")\n",
    "fight_details_tableau = pd.merge_asof(fight_details_tableau, snapshot_no_dups, left_on='event_date', right_on='date', left_by='opponent_name_clean',\n",
    "                                      right_by='fighter')\n",
    "\n",
    "fight_details_tableau = pd.merge_asof(fight_details_tableau, snapshot_no_dups, left_on='event_date', right_on='date', left_by='opponent_name_flipped_clean',\n",
    "                                      right_by='fighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_details_tableau['opponent_rank'] = fight_details_tableau[['rank_x','rank_y']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine result for each fighter and fight combination (win/loss/draw)\n",
    "fight_details_tableau['result'] = np.where(fight_details_tableau['winner_id'].isin(['NC', 'Draw']), fight_details_tableau['winner_id'],\n",
    "                                           np.where(fight_details_tableau['winner_id']==fight_details_tableau['fighter_id'], 'Win', 'Loss')\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bonus detail column considering whether the fighter won or loss the fight\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau['bonus'].str.split(', ')\n",
    "\n",
    "bonus_dict = {'winner' : {'belt' : 'Belt',\n",
    "                          'ko' : 'KO',\n",
    "                          'sub' : 'SUB',\n",
    "                          'fight' : 'FOTN',\n",
    "                          'perf' : 'POTN'\n",
    "                         },\n",
    "              'loser' : {'belt' : '',\n",
    "                         'ko' : '',\n",
    "                         'sub' : '',\n",
    "                         'fight' : 'FOTN',\n",
    "                         'perf' : ''\n",
    "                        }\n",
    "             }\n",
    "\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau.apply(lambda x: [] if x['bonus_detail']==None else \n",
    "                                                                    [bonus_dict['winner' if x['result']=='Win' else 'loser'][i] for i in x['bonus_detail']], axis=1)\n",
    "\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau['bonus_detail'].str.join(', ').str.strip().str.strip(',')\n",
    "fight_details_tableau['bonus_detail'] = np.where(fight_details_tableau['bonus_detail']=='', None, fight_details_tableau['bonus_detail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tableau table to only necessary columns\n",
    "tableau_fight_cols = ['fighter_id', 'fight_id', 'opponent_name', 'opponent_rank', 'weightclass', 'event_date', 'recency', \n",
    "                      'rds_sched', 'rd_ended', 'result', 'method', 'bonus_detail']\n",
    "fight_details_tableau = fight_details_tableau[tableau_fight_cols]\n",
    "fight_details_tableau = fight_details_tableau.merge(merged_metrics_by_fight, on=['fight_id', 'fighter_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Historical Rankings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean snapshots and fighter_details columns for merging fighter_ids\n",
    "clean_column(snapshots, 'fighter')\n",
    "\n",
    "fighter_details_tableau['full_name_clean'] = fighter_details_tableau['full_name']\n",
    "fighter_details_tableau['full_name_clean'] = fighter_details_tableau['full_name_clean'].replace(name_replace)\n",
    "clean_column(fighter_details_tableau, 'full_name_clean')\n",
    "\n",
    "clean_column(fighter_details_tableau, 'full_name_flipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge fighter ids where possible\n",
    "snapshots = snapshots.merge(fighter_details_tableau[['full_name_flipped', 'fighter_id']], left_on='fighter', right_on='full_name_flipped', how='left')\n",
    "snapshots = snapshots.merge(fighter_details_tableau[['full_name_clean', 'fighter_id']], left_on='fighter', right_on='full_name_clean', how='left')\n",
    "\n",
    "snapshots['fighter_id'] = np.where(snapshots['fighter_id_x'].isnull(), snapshots['fighter_id_y'], snapshots['fighter_id_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns for Tableau\n",
    "rankings_tableau = snapshots[['date', 'division', 'rank', 'fighter_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Tableau columns for fighter details table\n",
    "fighter_details_tableau = fighter_details_tableau[fighter_cols + ['top_cluster_all', 'top_cluster_past_10', 'top_cluster_past_5'] + ['full_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a blank row for use in the fighter selection parameter in Tableau\n",
    "fighter_details_tableau.loc[fighter_details_tableau.shape[0]] = [None] * len(fighter_details_tableau.columns)\n",
    "fighter_details_tableau.iloc[-1, -1] = '(None Selected)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Upcoming Event*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request upcoming events page\n",
    "page = requests.get('http://ufcstats.com/statistics/events/upcoming').text\n",
    "soup = BeautifulSoup(page, 'html5lib')\n",
    "\n",
    "# Request html for the next event only\n",
    "next_event = soup.find('table').find('a').get('href')\n",
    "\n",
    "page = requests.get(next_event).text\n",
    "soup = BeautifulSoup(page, 'html5lib')\n",
    "\n",
    "# Get fighter details for next event\n",
    "fighters = soup.find('table').find_all('a')\n",
    "\n",
    "matchups = []\n",
    "\n",
    "for i in range(0, len(fighters), 3):\n",
    "    fighter_1 = fighters[i].text.strip()\n",
    "    fighter_2 = fighters[i + 1].text.strip()\n",
    "    \n",
    "    matchups.append(fighter_1 + ' vs. ' + fighter_2)\n",
    "\n",
    "# Save matchups for next event to a dataframe\n",
    "tableau_matchups = pd.DataFrame({'Matchup' : matchups, 'Order' : range(len(matchups))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save Tables to Excel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_metrics_tableau.to_excel('tableau_fighter_metrics.xlsx', sheet_name='fighter_metrics')\n",
    "cluster_breakdown_tableau.to_excel('tableau_cluster_breakdowns.xlsx', sheet_name='clusters')\n",
    "fighter_details_tableau.to_excel('tableau_fighter_details.xlsx', sheet_name='fighter_details')\n",
    "fight_details_tableau.to_excel('tableau_fight_details.xlsx', sheet_name='fight_details')\n",
    "tableau_matchups.to_excel('tableau_matchups.xlsx', sheet_name='matchups', header=True)\n",
    "rankings_tableau.to_excel('tableau_rankings.xlsx', sheet_name='rankings', header=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "from UFCStats.queries import DatabaseQuery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "\n",
    "## Run Database Queries\n",
    "\n",
    "# Run queries to add db data to pandas dataframes\n",
    "DQ = DatabaseQuery()\n",
    "\n",
    "def query_to_df(query):\n",
    "    df = pd.DataFrame(query.fetchall())\n",
    "    df.columns = query.keys()\n",
    "    return df\n",
    "\n",
    "# Query database for fight details\n",
    "fight_cols = ['fight_id', 'event_id', 'weightclass', 'rds_sched', 'rd_ended', 'method', 'bonus', \n",
    "              'fighter_1_id', 'fighter_2_id', 'winner_id', 'tapology_rank', 'deductions']\n",
    "\n",
    "fight_col_str = ', '.join(fight_cols)\n",
    "\n",
    "fight_details = query_to_df(DQ.engine.execute('SELECT ' + fight_col_str + ' FROM fights'))\n",
    "\n",
    "# Query database for round information\n",
    "round_details = query_to_df(DQ.engine.execute('SELECT rd_id, fight_id, rd_num, rd_length FROM rounds'))\n",
    "\n",
    "# Query database for event dates\n",
    "event_dates = query_to_df(DQ.engine.execute('SELECT event_id, event_date FROM events'))\n",
    "\n",
    "# Query database for fighter information\n",
    "fighter_details = query_to_df(DQ.engine.execute('SELECT * FROM fighters'))\n",
    "\n",
    "# Query database for fight statistics by round\n",
    "result_cols = ['rd_id', 'fighter_id', 'kd', 'sig_head_land', 'sig_head_att', 'sig_body_land', \n",
    "               'sig_body_att', 'sig_leg_land', 'sig_leg_att', 'sig_dist_land', 'sig_dist_att',\n",
    "               'sig_clinch_land', 'sig_clinch_att', 'sig_ground_land', 'sig_ground_att', \n",
    "               'total_strike_land', 'total_strike_att', 'takedown_land', 'takedown_att', 'sub_att',\n",
    "               'reversals', 'ctrl_time', 'kd_taken', 'sig_head_taken', 'sig_head_seen', \n",
    "               'sig_body_taken', 'sig_body_seen', 'sig_leg_taken', 'sig_leg_seen', 'sig_dist_taken',\n",
    "               'sig_dist_seen', 'sig_clinch_taken', 'sig_clinch_seen', 'sig_ground_taken', \n",
    "               'sig_ground_seen', 'total_strike_taken', 'total_strike_seen', 'takedown_taken', \n",
    "               'takedown_seen', 'sub_seen', 'reversals_taken', 'ctrl_time_taken']\n",
    "\n",
    "result_col_str = ', '.join(result_cols)\n",
    "\n",
    "stats_by_round = query_to_df(DQ.engine.execute('SELECT ' + result_col_str + ' FROM round_results'))\n",
    "\n",
    "## Clean Up Stats By Round\n",
    "\n",
    "# Add columns for significant strikes landed and attempted by the fighter and the opponent\n",
    "stats_by_round['total_sig_land'] = stats_by_round['sig_head_land'] + stats_by_round['sig_body_land'] + stats_by_round['sig_leg_land']\n",
    "stats_by_round['total_sig_att'] = stats_by_round['sig_head_att'] + stats_by_round['sig_body_att'] + stats_by_round['sig_leg_att']\n",
    "stats_by_round['total_sig_land_opp'] = stats_by_round['sig_head_taken'] + stats_by_round['sig_body_taken'] + stats_by_round['sig_leg_taken']\n",
    "stats_by_round['total_sig_att_opp'] = stats_by_round['sig_head_seen'] + stats_by_round['sig_body_seen'] + stats_by_round['sig_leg_seen']\n",
    "\n",
    "# Merge round number and round length to fight stats table\n",
    "stats_by_round = stats_by_round.merge(round_details[['rd_id', 'rd_num', 'rd_length']],\n",
    "                                      on='rd_id',\n",
    "                                      how='left'\n",
    "                                     )\n",
    "\n",
    "# Drop all rounds where control time was not provided on UFCStats.com (NaN)\n",
    "stats_by_round.dropna(subset=['ctrl_time', 'ctrl_time_taken'], inplace=True)\n",
    "\n",
    "# Create columns for neutral time and control time plus neutral time\n",
    "stats_by_round['ctrl_plus_neutral'] = stats_by_round['rd_length'] - stats_by_round['ctrl_time_taken']\n",
    "stats_by_round['neutral_time'] = stats_by_round['ctrl_plus_neutral'] - stats_by_round['ctrl_time']\n",
    "\n",
    "## Determine Recency of Fights\n",
    "\n",
    "# Create fight recency table, showing an integer representing how fights into the past (most recent fight = 1)\n",
    "f1_fights = fight_details[['fight_id', 'event_id', 'fighter_1_id']].rename(columns={'fighter_1_id' : 'fighter_id'})\n",
    "f2_fights = fight_details[['fight_id', 'event_id', 'fighter_2_id']].rename(columns={'fighter_2_id' : 'fighter_id'})\n",
    "\n",
    "fight_recency = pd.concat([f1_fights, f2_fights]).reset_index(drop=True)\n",
    "fight_recency['fight_fighter'] = fight_recency['fight_id'] + '-' + fight_recency['fighter_id']\n",
    "fight_recency = fight_recency.merge(event_dates, on='event_id').sort_values(['fighter_id', 'event_date'], ascending=False)\n",
    "\n",
    "fight_recency['recency'] = fight_recency.groupby('fighter_id').cumcount() + 1\n",
    "\n",
    "# Create fight_id column and merge rounds scheduled\n",
    "stats_by_round['fight_id'] = stats_by_round['rd_id'].str.split('-').str[0]\n",
    "stats_by_round= stats_by_round.merge(fight_details[['fight_id', 'rds_sched']], on='fight_id')\n",
    "\n",
    "# Group round stats by fight for later use\n",
    "grouped_by_fight = stats_by_round.groupby(['fighter_id', 'fight_id']).sum().reset_index()\n",
    "\n",
    "# Merge recency information to stats_by_round table and grouped_by_fight table\n",
    "stats_by_round['fight_fighter'] = stats_by_round['fight_id'] + '-' + stats_by_round['fighter_id']\n",
    "stats_by_round = stats_by_round.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                      on='fight_fighter')\n",
    "\n",
    "grouped_by_fight['fight_fighter'] = grouped_by_fight['fight_id'] + '-' + grouped_by_fight['fighter_id']\n",
    "grouped_by_fight = grouped_by_fight.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                          on='fight_fighter')\n",
    "\n",
    "## Group Stats by Fighter and Round of the Fight\n",
    "\n",
    "def group_stats(stats_by_round, recency_max=1000):\n",
    "    \"\"\"\n",
    "    Group stats by round and fighter, filtered by provided recency.\n",
    "    \"\"\"\n",
    "    stats_by_round = stats_by_round[stats_by_round['recency'] <= recency_max]\n",
    "    grouped_by_round = stats_by_round.groupby(['fighter_id', 'rd_num']).sum().reset_index()\n",
    "    grouped_by_fighter = stats_by_round.groupby('fighter_id').sum().reset_index()\n",
    "    \n",
    "    return grouped_by_round, grouped_by_fighter\n",
    "\n",
    "grouped_by_round_all, grouped_by_fighter_all = group_stats(stats_by_round.copy())\n",
    "grouped_by_round_past_10, grouped_by_fighter_past_10 = group_stats(stats_by_round.copy(), 10)\n",
    "grouped_by_round_past_5, grouped_by_fighter_past_5 = group_stats(stats_by_round.copy(), 5)\n",
    "\n",
    "## Calculate Clustering Metrics\n",
    "\n",
    "#### Per Minute of Control/Neutral Time\n",
    "\n",
    "def per_min_ctrl_neutral(grouped_by_fighter, by_fight=False): \n",
    "    # Calculate stats per minute of control/neutral time\n",
    "    per_ctrl_plus_neutral_cols = ['fighter_id', 'kd', 'kd_taken', 'total_sig_land', 'total_sig_att', 'total_strike_land', 'total_strike_att',\n",
    "                                  'total_sig_land_opp', 'total_strike_taken', 'sub_att', 'ctrl_plus_neutral']\n",
    "    \n",
    "    # New column names\n",
    "    new_cols = ['fighter_id', 'kd_per_min', 'kd_taken_per_min', 'sig_land_per_min', 'sig_att_per_min', 'strike_land_per_min',\n",
    "                'strike_att_per_min', 'sig_absorbed_per_min', 'strike_absorbed_per_min', 'sub_att_per_min', 'ctrl_plus_neutral'\n",
    "               ]\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_ctrl_plus_neutral_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "\n",
    "    per_ctrl_plus_neutral = grouped_by_fighter[per_ctrl_plus_neutral_cols].copy(deep=True)\n",
    "\n",
    "    per_ctrl_plus_neutral.iloc[:, offset:] = per_ctrl_plus_neutral.iloc[:, offset:].div(per_ctrl_plus_neutral['ctrl_plus_neutral'], axis=0).multiply(60, axis=0)\n",
    "\n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_ctrl_plus_neutral.columns = new_cols\n",
    "    \n",
    "    return per_ctrl_plus_neutral\n",
    "\n",
    "per_ctrl_plus_neutral_all = per_min_ctrl_neutral(grouped_by_fighter_all)\n",
    "per_ctrl_plus_neutral_past_10 = per_min_ctrl_neutral(grouped_by_fighter_past_10)\n",
    "per_ctrl_plus_neutral_past_5 = per_min_ctrl_neutral(grouped_by_fighter_past_5)\n",
    "\n",
    "per_ctrl_plus_neutral_by_fight = per_min_ctrl_neutral(grouped_by_fight, True)\n",
    "\n",
    "#### Per Minute of Neutral Time\n",
    "\n",
    "def per_min_neutral(grouped_by_fighter, by_fight=False):\n",
    "    # Calculate stats per minute of neutral time\n",
    "    per_neutral_cols = ['fighter_id', 'takedown_att', 'takedown_land', 'takedown_taken', 'neutral_time']\n",
    "\n",
    "    # Renaming columns\n",
    "    new_cols = ['fighter_id', 'takedown_att_per_min', 'takedown_land_per_min', 'takedown_absorbed_per_min', 'neutral_time']\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_neutral_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "    \n",
    "    per_neutral = grouped_by_fighter[per_neutral_cols].copy(deep=True)\n",
    "\n",
    "    per_neutral.iloc[:, offset:] = per_neutral.iloc[:, offset:].div(per_neutral['neutral_time'], axis=0).multiply(60, axis=0)\n",
    "\n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_neutral.columns = new_cols\n",
    "    \n",
    "    return per_neutral\n",
    "\n",
    "per_neutral_all = per_min_neutral(grouped_by_fighter_all)\n",
    "per_neutral_past_10 = per_min_neutral(grouped_by_fighter_past_10)\n",
    "per_neutral_past_5 = per_min_neutral(grouped_by_fighter_past_5)\n",
    "\n",
    "per_neutral_by_fight = per_min_neutral(grouped_by_fight, True)\n",
    "\n",
    "#### Per Minute of Total Time\n",
    "\n",
    "def per_min_total(grouped_by_fighter, by_fight=False):\n",
    "    # Calculate stats per minute of total time (rd_length)\n",
    "    per_total_time_cols = ['fighter_id', 'ctrl_time', 'ctrl_time_taken', 'rd_length']\n",
    "\n",
    "    # Renaming columns\n",
    "    new_cols = ['fighter_id', 'ctrl_time_per_min', 'ctrl_time_opp_per_min', 'rd_length']\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if by_fight:\n",
    "        per_total_time_cols.insert(1, 'fight_id')\n",
    "        new_cols.insert(1, 'fight_id')\n",
    "        offset = 2\n",
    "    \n",
    "    per_total_time = grouped_by_fighter[per_total_time_cols].copy(deep=True)\n",
    "\n",
    "    per_total_time.iloc[:, offset:] = per_total_time.iloc[:, offset:].div(per_total_time['rd_length'], axis=0).multiply(60, axis=0)\n",
    "    \n",
    "    # Rename columns to reflect \"per minute\"\n",
    "    per_total_time.columns = new_cols\n",
    "    \n",
    "    return per_total_time\n",
    "\n",
    "per_total_time_all = per_min_total(grouped_by_fighter_all)\n",
    "per_total_time_past_10 = per_min_total(grouped_by_fighter_past_10)\n",
    "per_total_time_past_5 = per_min_total(grouped_by_fighter_past_5)\n",
    "\n",
    "per_total_time_by_fight = per_min_total(grouped_by_fight, True)\n",
    "\n",
    "#### Fight Metric Ratios\n",
    "\n",
    "def metric_ratio_calcs(grouped_by_fighter, by_fight=False):\n",
    "    # Copy the stats by fighter table\n",
    "    metric_ratios = grouped_by_fighter.copy(deep=True)\n",
    "\n",
    "    # Create fight metric ratio columns\n",
    "    metric_ratios['ctrl_time_ratio'] = metric_ratios['ctrl_time'] / metric_ratios['ctrl_time_taken']\n",
    "    metric_ratios['takedown_perc'] = metric_ratios['takedown_land'] / metric_ratios['takedown_att']\n",
    "    metric_ratios['opp_takedown_perc'] = metric_ratios['takedown_taken'] / metric_ratios['takedown_seen']\n",
    "    metric_ratios['leg_strike_rate'] = metric_ratios['sig_leg_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['body_strike_rate'] = metric_ratios['sig_body_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['head_strike_rate'] = metric_ratios['sig_head_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['dist_strike_rate'] = metric_ratios['sig_dist_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['clinch_strike_rate'] = metric_ratios['sig_clinch_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['ground_strike_rate'] = metric_ratios['sig_ground_att'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['leg_strike_acc'] = metric_ratios['sig_leg_land'] / metric_ratios['sig_leg_att']\n",
    "    metric_ratios['body_strike_acc'] = metric_ratios['sig_body_land'] / metric_ratios['sig_body_att']\n",
    "    metric_ratios['head_strike_acc'] = metric_ratios['sig_head_land'] / metric_ratios['sig_head_att']\n",
    "    metric_ratios['dist_strike_acc'] = metric_ratios['sig_dist_land'] / metric_ratios['sig_dist_att']\n",
    "    metric_ratios['clinch_strike_acc'] = metric_ratios['sig_clinch_land'] / metric_ratios['sig_clinch_att']\n",
    "    metric_ratios['ground_strike_acc'] = metric_ratios['sig_ground_land'] / metric_ratios['sig_ground_att']\n",
    "    metric_ratios['sig_strike_acc'] = metric_ratios['total_sig_land'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['opp_sig_strike_acc'] = metric_ratios['total_sig_land_opp'] / metric_ratios['total_sig_att_opp']\n",
    "    metric_ratios['total_strike_acc'] = metric_ratios['total_strike_land'] / metric_ratios['total_strike_att']\n",
    "    metric_ratios['opp_total_strike_acc'] = metric_ratios['total_strike_taken'] / metric_ratios['total_strike_seen']\n",
    "    metric_ratios['kd_per_sig_strike'] = metric_ratios['kd'] / metric_ratios['total_sig_att']\n",
    "    metric_ratios['kd_per_sig_head_strike'] = metric_ratios['kd'] / metric_ratios['sig_head_att']\n",
    "    metric_ratios['opp_kd_per_sig_strike'] = metric_ratios['kd_taken'] / metric_ratios['total_sig_att_opp']\n",
    "    metric_ratios['opp_kd_per_sig_head_strike'] = metric_ratios['kd_taken'] / metric_ratios['sig_head_seen']\n",
    "    \n",
    "    if by_fight:\n",
    "        metric_ratios = metric_ratios[metric_ratio_cols_by_fight]\n",
    "    else:\n",
    "        metric_ratios = metric_ratios[metric_ratio_cols]\n",
    "    \n",
    "    return metric_ratios\n",
    "\n",
    "# Filter the metric ratios table to ratio columns only\n",
    "metric_ratio_cols = ['fighter_id',\n",
    "                     'ctrl_time_ratio',\n",
    "                     'takedown_perc',\n",
    "                     'opp_takedown_perc',\n",
    "                     'leg_strike_rate',\n",
    "                     'body_strike_rate',\n",
    "                     'head_strike_rate',\n",
    "                     'dist_strike_rate',\n",
    "                     'clinch_strike_rate',\n",
    "                     'ground_strike_rate',\n",
    "                     'leg_strike_acc',\n",
    "                     'body_strike_acc',\n",
    "                     'head_strike_acc',\n",
    "                     'dist_strike_acc',\n",
    "                     'clinch_strike_acc',\n",
    "                     'ground_strike_acc',\n",
    "                     'sig_strike_acc',\n",
    "                     'opp_sig_strike_acc',\n",
    "                     'total_strike_acc',\n",
    "                     'opp_total_strike_acc',\n",
    "                     'kd_per_sig_strike',\n",
    "                     'kd_per_sig_head_strike',\n",
    "                     'opp_kd_per_sig_strike',\n",
    "                     'opp_kd_per_sig_head_strike']\n",
    "\n",
    "metric_ratio_cols_by_fight = metric_ratio_cols.copy()\n",
    "metric_ratio_cols_by_fight.insert(1, 'fight_id')\n",
    "\n",
    "metric_ratios_all = metric_ratio_calcs(grouped_by_fighter_all)\n",
    "metric_ratios_past_10 = metric_ratio_calcs(grouped_by_fighter_past_10)\n",
    "metric_ratios_past_5 = metric_ratio_calcs(grouped_by_fighter_past_5)\n",
    "\n",
    "metric_ratios_by_fight = metric_ratio_calcs(grouped_by_fight, True)\n",
    "\n",
    "#### Finish Metrics\n",
    "\n",
    "def finish_metrics(finish_details, grouped_by_fighter, recency_max=1000):\n",
    "    # Group finish details by method and count instances of winner and method combinations\n",
    "    finish_details = finish_details[finish_details['recency'] <= recency_max].copy()\n",
    "    finish_counts = finish_details.groupby(['fighter_id', 'result_method']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "    # Merge sub attempts columns\n",
    "    sub_cols = ['fighter_id', 'sub_att', 'sub_seen']\n",
    "    finish_counts = finish_counts.merge(grouped_by_fighter[sub_cols]) \n",
    "\n",
    "    # Create aggregate columns for win/loss rate calculations\n",
    "    finish_counts['finish_wins'] = finish_counts['win - tko'] + finish_counts['win - sub']\n",
    "    finish_counts['finish_losses'] = finish_counts['loss - tko'] + finish_counts['loss - sub']\n",
    "    finish_counts['num_fights'] = finish_counts.iloc[:, 1:8].sum(axis=1)\n",
    "    finish_counts['num_wins'] = finish_counts['win - decision'] + finish_counts['win - sub'] + finish_counts['win - tko']\n",
    "    finish_counts['num_losses'] = finish_counts['loss - decision'] + finish_counts['loss - sub'] + finish_counts['loss - tko']\n",
    "\n",
    "    # Calculate LOSS rates by different methods, both in terms of versus total fights and total wins\n",
    "    finish_counts['tko_win_per_fight'] = finish_counts['win - tko'] / finish_counts['num_fights']\n",
    "    finish_counts['sub_win_per_fight'] = finish_counts['win - sub'] / finish_counts['num_fights']\n",
    "    finish_counts['dec_win_per_fight'] = finish_counts['win - decision'] / finish_counts['num_fights']\n",
    "    finish_counts['tko_win_per_win'] = finish_counts['win - tko'] / finish_counts['num_wins']\n",
    "    finish_counts['sub_win_per_win'] = finish_counts['win - sub'] / finish_counts['num_wins']\n",
    "    finish_counts['dec_win_per_win'] = finish_counts['win - decision'] / finish_counts['num_wins']\n",
    "\n",
    "    # Calculate LOSS rates by different methods, both in terms of versus total fights and total wins\n",
    "    finish_counts['tko_loss_per_fight'] = finish_counts['loss - tko'] / finish_counts['num_fights']\n",
    "    finish_counts['sub_loss_per_fight'] = finish_counts['loss - sub'] / finish_counts['num_fights']\n",
    "    finish_counts['dec_loss_per_fight'] = finish_counts['loss - decision'] / finish_counts['num_fights']\n",
    "    finish_counts['tko_loss_per_loss'] = finish_counts['loss - tko'] / finish_counts['num_losses']\n",
    "    finish_counts['sub_loss_per_loss'] = finish_counts['loss - sub'] / finish_counts['num_losses']\n",
    "    finish_counts['dec_loss_per_loss'] = finish_counts['loss - decision'] / finish_counts['num_losses']\n",
    "\n",
    "    # Calculate submission success rate for fighter and opponent  (DOESN'T CALC PROPERLY)\n",
    "    #finish_counts['sub_success_rate'] = finish_counts['win - sub'] / finish_counts['sub_att']\n",
    "    #finish_counts['opp_sub_success_rate'] = finish_counts['loss - sub'] / finish_counts['sub_seen']\n",
    "\n",
    "    # Calculate total finish rate and opponent finish rate\n",
    "    finish_counts['finish_rate'] = finish_counts['finish_wins'] / finish_counts['num_fights']\n",
    "    finish_counts['opp_finish_rate'] = finish_counts['finish_losses'] / finish_counts['num_fights']\n",
    "\n",
    "    # Filter to final columns\n",
    "    final_finish_cols = ['fighter_id', 'num_fights', 'tko_win_per_fight', 'sub_win_per_fight', 'dec_win_per_fight',\n",
    "                         'tko_win_per_win', 'sub_win_per_win', 'dec_win_per_win', 'tko_loss_per_fight',\n",
    "                         'sub_loss_per_fight', 'dec_loss_per_fight', 'tko_loss_per_loss', 'sub_loss_per_loss',\n",
    "                         'dec_loss_per_loss', 'finish_rate',\n",
    "                         'opp_finish_rate'\n",
    "                        ]\n",
    "\n",
    "    finish_counts = finish_counts[final_finish_cols]\n",
    "    \n",
    "    return finish_counts\n",
    "\n",
    "# Adjust fight detail table such that each row represents a fighter's performance in a single fight\n",
    "finish_details_f1 = fight_details[['fight_id', 'method', 'fighter_1_id', 'winner_id']].copy()\n",
    "finish_details_f2 = fight_details[['fight_id', 'method', 'fighter_2_id', 'winner_id']].copy()\n",
    "\n",
    "finish_details_f1.columns = ['fight_id', 'method', 'fighter_id', 'winner_id']\n",
    "finish_details_f2.columns = ['fight_id', 'method', 'fighter_id', 'winner_id']\n",
    "\n",
    "finish_details = pd.concat([finish_details_f1, finish_details_f2]).sort_values('fight_id').reset_index(drop=True)\n",
    "\n",
    "# Replace values in the method column\n",
    "method_dict = {'Decision - Unanimous' : 'decision',\n",
    "               'Decision - Split' : 'decision',\n",
    "               'Decision - Majority' : 'decision',\n",
    "               'KO/TKO' : 'tko',\n",
    "               'TKO - Doctor\\'s Stoppage' : 'tko',\n",
    "               'Could Not Continue\t' : 'exclude',\n",
    "               'Could Not Continue' : 'exclude',\n",
    "               'Overturned' : 'exclude',\n",
    "               'Other' : 'exclude',\n",
    "               'DQ' : 'exclude',\n",
    "               'Submission' : 'sub'\n",
    "              }\n",
    "\n",
    "finish_details.replace({'method': method_dict}, inplace=True)\n",
    "\n",
    "# Add results column to reflect win/loss/draw and method\n",
    "finish_details['result'] = np.where(finish_details['fighter_id']==finish_details['winner_id'], 'win',\n",
    "                                    np.where(finish_details['winner_id']=='Draw', 'draw',\n",
    "                                             np.where(finish_details['winner_id']=='NC', 'no contest', 'loss')                                                    \n",
    "                                            )\n",
    "                                   )\n",
    "\n",
    "finish_details_by_fight = finish_details.copy(deep=True)\n",
    "\n",
    "finish_details = finish_details[(~finish_details['result'].isin(['no contest'])) &\n",
    "                                (~finish_details['method'].isin(['exclude']))\n",
    "                               ]\n",
    "\n",
    "finish_details['result_method'] = finish_details['result'] + ' - ' + finish_details['method']\n",
    "finish_details_by_fight['result_method']=np.where(finish_details_by_fight['result']=='no contest', 'no contest',\n",
    "                                                  finish_details_by_fight['result'] + ' - ' + finish_details_by_fight['method']\n",
    "                                                 )\n",
    "\n",
    "# Merge recency information to finish_details table\n",
    "finish_details['fight_fighter'] = finish_details['fight_id'] + '-' + finish_details['fighter_id']\n",
    "finish_details = finish_details.merge(fight_recency[['fight_fighter', 'event_date', 'recency']],\n",
    "                                      on='fight_fighter')\n",
    "\n",
    "finish_counts_all = finish_metrics(finish_details.copy(), grouped_by_fighter_all)\n",
    "finish_counts_past_10 = finish_metrics(finish_details.copy(), grouped_by_fighter_past_10, 10)\n",
    "finish_counts_past_5 = finish_metrics(finish_details.copy(), grouped_by_fighter_past_5, 5)\n",
    "\n",
    "# Create finish table by fight\n",
    "finish_by_fight = finish_details_by_fight.pivot_table(index=['fight_id', 'fighter_id'], columns='result_method', values='result', aggfunc='count').reset_index()\n",
    "finish_by_fight.fillna(0, inplace=True)\n",
    "\n",
    "#### Control and Strike Pacing\n",
    "\n",
    "# Tag rounds as early or late\n",
    "stats_by_round['early_late'] = np.where(stats_by_round['rds_sched']=='3', np.where(stats_by_round['rd_num']<=2, 'early', 'late'),\n",
    "                                        np.where(stats_by_round['rd_num']<=3, 'early', 'late')\n",
    "                                       )\n",
    "\n",
    "# Establish columns for pace calculations\n",
    "pace_cols = ['fighter_id', 'early_late', 'rd_length', 'ctrl_time', 'ctrl_time_taken', 'total_sig_land', 'total_sig_land_opp']\n",
    "\n",
    "def pace_calcs(stats_by_round, recency_max=1000):\n",
    "    \n",
    "    stats_by_round = stats_by_round[stats_by_round['recency'] <= recency_max]\n",
    "    pace_metrics = stats_by_round[pace_cols].groupby(['fighter_id', 'early_late']).sum().reset_index()\n",
    "    \n",
    "    # Split into two tables, early and late rounds\n",
    "    pace_metrics = pace_metrics.sort_values(['early_late', 'fighter_id'])\n",
    "    early = pace_metrics[pace_metrics['early_late']=='early'].reset_index(drop=True)\n",
    "    late = pace_metrics[pace_metrics['early_late']=='late'].reset_index(drop=True)\n",
    "\n",
    "    # Rename columns\n",
    "    early.columns = ['fighter_id', 'early_late', 'rd_length_early', 'ctrl_time_early', 'ctrl_time_taken_early', 'total_sig_land_early', 'total_sig_land_opp_early']\n",
    "    late.columns = ['fighter_id', 'early_late', 'rd_length_late', 'ctrl_time_late', 'ctrl_time_taken_late', 'total_sig_land_late', 'total_sig_land_opp_late']\n",
    "\n",
    "    # Recombine early and late metrics\n",
    "    pace_metrics = late.merge(early, on='fighter_id')\n",
    "\n",
    "    # Calculate pacing metrics for control and strike rates in early vs late rounds\n",
    "    pace_metrics['control_rate_early'] = pace_metrics['ctrl_time_early'] / pace_metrics['rd_length_early']\n",
    "    pace_metrics['control_rate_late'] = pace_metrics['ctrl_time_late'] / pace_metrics['rd_length_late']\n",
    "    pace_metrics['control_rate_late_vs_early'] = pace_metrics['control_rate_late'] / pace_metrics['control_rate_early']\n",
    "    pace_metrics['sig_strike_rate_early'] = pace_metrics['total_sig_land_early'] / pace_metrics['rd_length_early']\n",
    "    pace_metrics['sig_strike_rate_late'] = pace_metrics['total_sig_land_late'] / pace_metrics['rd_length_late']\n",
    "    pace_metrics['sig_strike_rate_late_vs_early'] = pace_metrics['sig_strike_rate_late'] / pace_metrics['sig_strike_rate_early']\n",
    "\n",
    "    # Filter to the final table of pace metrics\n",
    "    final_pace_cols = ['fighter_id', 'control_rate_late_vs_early', 'sig_strike_rate_late_vs_early']\n",
    "    pace_metrics = pace_metrics[final_pace_cols]\n",
    "    \n",
    "    return pace_metrics\n",
    "\n",
    "pace_metrics_all = pace_calcs(stats_by_round.copy())\n",
    "pace_metrics_past_10 = pace_calcs(stats_by_round.copy(), 10)\n",
    "pace_metrics_past_5 = pace_calcs(stats_by_round.copy(), 5)\n",
    "\n",
    "## Merge Clustering Metrics\n",
    "\n",
    "def merge_metrics(finish_counts, per_ctrl_plus_neutral, per_neutral, per_total_time, metric_ratios, pace_metrics=None, by_fight=False):\n",
    "    \"\"\"\n",
    "    Merge all fighter metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    if by_fight:\n",
    "        merge_col = ['fighter_id',  'fight_id']\n",
    "    else:\n",
    "        merge_col = 'fighter_id'\n",
    "    \n",
    "    merged_metrics = finish_counts.copy()\n",
    "    merged_metrics = merged_metrics.merge(per_ctrl_plus_neutral.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(per_neutral.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(per_total_time.iloc[:, 0:-1], on=merge_col, how='left')\n",
    "    merged_metrics = merged_metrics.merge(metric_ratios, on=merge_col, how='left')\n",
    "    \n",
    "    if by_fight==False:\n",
    "        merged_metrics = merged_metrics.merge(pace_metrics, on=merge_col, how='left')\n",
    "    \n",
    "    return merged_metrics\n",
    "\n",
    "merged_metrics_all = merge_metrics(finish_counts_all, per_ctrl_plus_neutral_all, per_neutral_all, \n",
    "                                   per_total_time_all, metric_ratios_all, pace_metrics_all)\n",
    "\n",
    "merged_metrics_past_10 = merge_metrics(finish_counts_past_10, per_ctrl_plus_neutral_past_10, per_neutral_past_10, \n",
    "                                       per_total_time_past_10, metric_ratios_past_10, pace_metrics_past_10)\n",
    "\n",
    "merged_metrics_past_5 = merge_metrics(finish_counts_past_5, per_ctrl_plus_neutral_past_5, per_neutral_past_5, \n",
    "                                      per_total_time_past_5, metric_ratios_past_5, pace_metrics_past_5)\n",
    "\n",
    "merged_metrics_by_fight = merge_metrics(finish_by_fight, per_ctrl_plus_neutral_by_fight, per_neutral_by_fight, \n",
    "                                        per_total_time_by_fight, metric_ratios_by_fight, by_fight=True)\n",
    "\n",
    "## Clean Merged Metrics\n",
    "\n",
    "def clean_up_metrics(merged_metrics):\n",
    "    \"\"\"\n",
    "    Replace nulls and infinities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace NaN with zero\n",
    "    merged_metrics = merged_metrics.fillna(0)\n",
    "    \n",
    "    # Replace infinity with zero\n",
    "    merged_metrics = merged_metrics.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    return merged_metrics\n",
    "\n",
    "# Clean up all fight metrics (nan, infinity)\n",
    "merged_metrics_all = clean_up_metrics(merged_metrics_all)\n",
    "merged_metrics_past_10 = clean_up_metrics(merged_metrics_past_10)\n",
    "merged_metrics_past_5 = clean_up_metrics(merged_metrics_past_5)\n",
    "merged_metrics_by_fight = clean_up_metrics(merged_metrics_by_fight)\n",
    "\n",
    "## Cluster Assignments\n",
    "\n",
    "### *Import Scaler, PCA, and K-Means Model*\n",
    "\n",
    "# Import K-Means model\n",
    "with open('nf_km_10.pickle', 'rb') as read_file:\n",
    "    km = pickle.load(read_file)\n",
    "    \n",
    "# Import PCA\n",
    "with open('nf_pca_fighter_style.pickle', 'rb') as read_file:\n",
    "    pca = pickle.load(read_file)\n",
    "    \n",
    "# Import Standard Scaler\n",
    "with open('nf_standard_scaler_fighter_style.pickle', 'rb') as read_file:\n",
    "    st_scale = pickle.load(read_file)\n",
    "\n",
    "### *Filter and Transform Data for Clustering*\n",
    "\n",
    "def scale_filter_and_transform(fight_metrics):\n",
    "    \"\"\"\n",
    "    Filter for clustering columns and transform using PCA used in initial cluster formation.\n",
    "    \"\"\"\n",
    "    \n",
    "    fight_metrics = fight_metrics[cluster_cols].copy()\n",
    "    fight_metrics_st = st_scale.transform(fight_metrics)\n",
    "    fight_metrics_pca = pca.transform(fight_metrics_st)\n",
    "    \n",
    "    return fight_metrics_pca\n",
    "\n",
    "cluster_cols = ['head_strike_rate', 'dist_strike_rate', 'sig_att_per_min',\n",
    "                'kd_per_sig_strike', 'sig_strike_acc', 'total_strike_acc',\n",
    "                'opp_kd_per_sig_strike', 'opp_sig_strike_acc', 'sig_absorbed_per_min',\n",
    "                'takedown_land_per_min', 'ctrl_time_per_min', 'sub_att_per_min',\n",
    "                'takedown_absorbed_per_min', 'opp_takedown_perc'\n",
    "               ]\n",
    "\n",
    "pca_all = scale_filter_and_transform(merged_metrics_all)\n",
    "pca_past_5 = scale_filter_and_transform(merged_metrics_past_5)\n",
    "pca_past_10 = scale_filter_and_transform(merged_metrics_past_10)\n",
    "\n",
    "## Cluster Breakdown by Fighter\n",
    "\n",
    "def cluster_breakdown(cluster_data_pca):\n",
    "    \"\"\"\n",
    "    For given PCA data, return a cluster percentage breakdown for each fighter.\n",
    "    \"\"\"\n",
    "    # Calculate Euclidean distance from fighters to each cluster\n",
    "    nodes_to_centroids = distance.cdist(cluster_data_pca, centroids, 'euclidean')\n",
    "    \n",
    "    # Set up dataframe of distances to cluster centroids\n",
    "    nodes_to_centroids_df = pd.DataFrame(nodes_to_centroids, columns=breakdown_cols)\n",
    "\n",
    "    # Convert distances to \"similiarity scores\"\n",
    "    nodes_to_centroids_df['max_distance'] = nodes_to_centroids_df.max(axis=1)\n",
    "    nodes_to_centroids_df = nodes_to_centroids_df.div(nodes_to_centroids_df['max_distance'], axis=0)\n",
    "    nodes_to_centroids_df = 1 - nodes_to_centroids_df\n",
    "\n",
    "    # Convert similarity scores to percentages for each cluster\n",
    "    nodes_to_centroids_df['sum'] = nodes_to_centroids_df.sum(axis=1)\n",
    "    nodes_to_centroids_df = nodes_to_centroids_df.div(nodes_to_centroids_df['sum'], axis=0)\n",
    "\n",
    "    # Eliminate unnecessary columns, calculate dominant cluster\n",
    "    cluster_breakdown = nodes_to_centroids_df[breakdown_cols]\n",
    "    cluster_breakdown['max_percentage'] = cluster_breakdown.max(axis=1)\n",
    "    cluster_breakdown['top_cluster'] = km.predict(cluster_data_pca)\n",
    "    \n",
    "    return cluster_breakdown\n",
    "\n",
    "# Pull centroid positions from K-Means model\n",
    "centroids = km.cluster_centers_\n",
    "\n",
    "# Establish columns for cluster breakdown dataframe\n",
    "breakdown_cols = ['Cluster 0',\n",
    "                  'Cluster 1',\n",
    "                  'Cluster 2',\n",
    "                  'Cluster 3',\n",
    "                  'Cluster 4',\n",
    "                  'Cluster 5',\n",
    "                  'Cluster 6',\n",
    "                  'Cluster 7',\n",
    "                  'Cluster 8',\n",
    "                  'Cluster 9',\n",
    "                 ]\n",
    "\n",
    "# Calculate cluster breakdowns\n",
    "cluster_breakdown_all = cluster_breakdown(pca_all)\n",
    "cluster_breakdown_past_10 = cluster_breakdown(pca_past_10)\n",
    "cluster_breakdown_past_5 = cluster_breakdown(pca_past_5)\n",
    "\n",
    "## Prepare Data for Tableau\n",
    "\n",
    "def stack_with_tag(data_list, tag_list):\n",
    "    \n",
    "    df = data_list[0].copy()\n",
    "    df['past_fights'] = tag_list[0]\n",
    "    \n",
    "    for i in range(1, len(data_list)):\n",
    "        df_2 = data_list[i].copy()\n",
    "        df_2['past_fights'] = tag_list[i]\n",
    "        df = pd.concat([df, df_2]).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "### *Fight Metrics*\n",
    "\n",
    "# Stack and tag fight metrics\n",
    "fighter_metrics_tableau = stack_with_tag([merged_metrics_all, merged_metrics_past_10, merged_metrics_past_5],\n",
    "                                         ['All', 'Past 10', 'Past 5'])\n",
    "\n",
    "### *Cluster Data*\n",
    "\n",
    "# Stack and tag cluster breakdowns\n",
    "cluster_breakdown_all['fighter_id'] = merged_metrics_all['fighter_id']\n",
    "cluster_breakdown_past_10['fighter_id'] = merged_metrics_past_10['fighter_id']\n",
    "cluster_breakdown_past_5['fighter_id'] = merged_metrics_past_5['fighter_id']\n",
    "\n",
    "cluster_breakdown_stacked = stack_with_tag([cluster_breakdown_all, cluster_breakdown_past_10, cluster_breakdown_past_5],\n",
    "                                           ['All', 'Past 10', 'Past 5'])\n",
    "\n",
    "# Melt table\n",
    "cluster_breakdown_tableau = cluster_breakdown_stacked[['fighter_id', 'past_fights']  + breakdown_cols].melt(id_vars=['fighter_id', 'past_fights'], \n",
    "                                                                                                            var_name='cluster',\n",
    "                                                                                                            value_name='percentage')\n",
    "# Save copy for later\n",
    "cluster_breakdown = cluster_breakdown_tableau.copy()\n",
    "\n",
    "# Map cluster values to cluster names:\n",
    "cluster_map = {'Cluster 0' : 'High Risk Sub Artist',\n",
    "               'Cluster 1' : 'Patient Power Puncher',\n",
    "               'Cluster 2' : 'Stick and Move',\n",
    "               'Cluster 3' : 'Pressure Wrestler',\n",
    "               'Cluster 4' : 'Head Hunting Wrestler',\n",
    "               'Cluster 5' : 'Glass Cannon',\n",
    "               'Cluster 6' : 'Stand and Bang',\n",
    "               'Cluster 7' : 'Grind It Out',\n",
    "               'Cluster 8' : 'Chinny Grappler',\n",
    "               'Cluster 9' : 'Tactician'\n",
    "              }\n",
    "\n",
    "cluster_breakdown_tableau['f1_cluster'] = cluster_breakdown_tableau['cluster'].map(cluster_map)\n",
    "cluster_breakdown_tableau['cluster'] = cluster_breakdown_tableau['cluster'].map(cluster_map)\n",
    "cluster_breakdown['cluster'] = cluster_breakdown['cluster'].map(cluster_map)\n",
    "\n",
    "# Grab top clusters for each fighter \n",
    "top_clusters = cluster_breakdown_all[['fighter_id', 'top_cluster']]\n",
    "top_clusters_past_10 = cluster_breakdown_past_10[['fighter_id', 'top_cluster']]\n",
    "top_clusters_past_5 = cluster_breakdown_past_5[['fighter_id', 'top_cluster']]\n",
    "\n",
    "# Map top clusters to cluster names\n",
    "cluster_map_int = {0 : 'High Risk Sub Artist',\n",
    "                   1 : 'Patient Power Puncher',\n",
    "                   2 : 'Stick and Move',\n",
    "                   3 : 'Pressure Wrestler',\n",
    "                   4 : 'Head Hunting Wrestler',\n",
    "                   5 : 'Glass Cannon',\n",
    "                   6 : 'Stand and Bang',\n",
    "                   7 : 'Grind It Out', \n",
    "                   8 : 'Chinny Grappler',\n",
    "                   9 : 'Tactician',\n",
    "                  }\n",
    "\n",
    "top_clusters['top_cluster'] = top_clusters['top_cluster'].map(cluster_map_int)\n",
    "top_clusters_past_10['top_cluster'] = top_clusters_past_10['top_cluster'].map(cluster_map_int)\n",
    "top_clusters_past_5['top_cluster'] = top_clusters_past_5['top_cluster'].map(cluster_map_int)\n",
    "\n",
    "# Start with fighter ID's\n",
    "style_matchups = fight_details[['fighter_1_id', 'fighter_2_id', 'winner_id']]\n",
    "\n",
    "# Add loser ID\n",
    "style_matchups['loser_id'] = np.where(style_matchups['winner_id']==style_matchups['fighter_1_id'],\n",
    "                                      style_matchups['fighter_2_id'], style_matchups['fighter_1_id'])\n",
    "\n",
    "# Merge number of fights and top clusters for winner and loser ID's\n",
    "style_matchups = style_matchups.merge(merged_metrics_all[['fighter_id', 'num_fights']], left_on='winner_id', right_on='fighter_id')\n",
    "style_matchups = style_matchups.merge(merged_metrics_all[['fighter_id', 'num_fights']], left_on='loser_id', right_on='fighter_id', suffixes=['_winner', '_loser'])\n",
    "\n",
    "style_matchups = style_matchups.merge(top_clusters, left_on='winner_id', right_on='fighter_id')\n",
    "style_matchups = style_matchups.merge(top_clusters, left_on='loser_id', right_on='fighter_id', suffixes=['_winner', '_loser'])\n",
    "\n",
    "style_matchups = style_matchups[(style_matchups['num_fights_winner']>=10) & (style_matchups['num_fights_loser']>=10)][['top_cluster_winner', 'top_cluster_loser']].reset_index(drop=True)\n",
    "\n",
    "# Group by winner and loser ID's to determine which clusters win over others in their matchups\n",
    "winners = style_matchups.groupby(['top_cluster_winner', 'top_cluster_loser']).size().unstack(fill_value=0)\n",
    "losers = style_matchups.groupby(['top_cluster_loser', 'top_cluster_winner']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate win percentage by cluster matchup\n",
    "win_percentage = winners / (winners + losers)\n",
    "\n",
    "# Tidy up win percentage, rename columns, and map to cluster labels\n",
    "win_percentage = win_percentage.reset_index().melt(id_vars='top_cluster_winner')\n",
    "win_percentage.columns = ['f1_cluster', 'f2_cluster', 'win_percentage']\n",
    "\n",
    "#win_percentage['f1_cluster'] = win_percentage['f1_cluster'].map(cluster_map)\n",
    "#win_percentage['f2_cluster'] = win_percentage['f2_cluster'].map(cluster_map)\n",
    "\n",
    "cluster_breakdown_tableau = cluster_breakdown_tableau.merge(win_percentage, on='f1_cluster')\n",
    "\n",
    "cluster_breakdown_tableau = cluster_breakdown_tableau.merge(cluster_breakdown[['fighter_id', 'past_fights', 'cluster', 'percentage']],\n",
    "                                                            left_on=['fighter_id', 'past_fights', 'f2_cluster'], \n",
    "                                                            right_on=['fighter_id', 'past_fights', 'cluster'],\n",
    "                                                            suffixes=['','_f2'])\n",
    "\n",
    "cluster_breakdown_tableau.drop(columns=['cluster_f2'], inplace=True)\n",
    "\n",
    "### *Fighter Details*\n",
    "\n",
    "# Set up fighter detail table\n",
    "fighter_cols = ['fighter_id', 'first_name', 'last_name', 'nickname', 'gender', 'reach', 'height', \n",
    "                'stance', 'wins', 'losses', 'draws', 'belt', 'last_fight_date', 'latest_weight_class']\n",
    "\n",
    "fighter_details_tableau = fighter_details[fighter_cols]\n",
    "fighter_details_tableau['full_name'] = np.where(fighter_details_tableau['first_name'].isnull(),\n",
    "                                                fighter_details_tableau['last_name'],\n",
    "                                                fighter_details_tableau['first_name'] + ' ' + fighter_details_tableau['last_name']\n",
    "                                               )\n",
    "\n",
    "# Included flipped name (last first) for merging with fighter rankings later\n",
    "fighter_details_tableau['full_name_flipped'] = np.where(fighter_details_tableau['first_name'].isnull(),\n",
    "                                                        fighter_details_tableau['last_name'],\n",
    "                                                        fighter_details_tableau['last_name'] + ' ' + fighter_details_tableau['first_name']\n",
    "                                               )\n",
    "\n",
    "# Merge top cluster detail (all, past 5, past 10) and set column names\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters, on='fighter_id')\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters_past_10, on='fighter_id', suffixes=('_all', '_past_10'))\n",
    "fighter_details_tableau = fighter_details_tableau.merge(top_clusters_past_10, on='fighter_id')\n",
    "fighter_details_tableau = fighter_details_tableau.rename(columns={'top_cluster' : 'top_cluster_past_5'})\n",
    "\n",
    "### *Fight Details*\n",
    "\n",
    "# Merge fight details to the fight recency table\n",
    "fight_detail_cols = ['fight_id', 'fighter_1_id', 'fighter_2_id', 'winner_id', 'weightclass', 'rds_sched', 'rd_ended', 'method', 'bonus']\n",
    "\n",
    "fight_details_tableau = fight_recency.merge(fight_details[fight_detail_cols], on='fight_id')\n",
    "\n",
    "# Determine opponent fighter_id\n",
    "fight_details_tableau['opponent_id'] = np.where(fight_details_tableau['fighter_id']==fight_details_tableau['fighter_1_id'], \n",
    "                                                fight_details_tableau['fighter_2_id'], fight_details_tableau['fighter_1_id'])\n",
    "\n",
    "# Add opponent full name to the fight details table\n",
    "fight_details_tableau = fight_details_tableau.merge(fighter_details_tableau[['fighter_id', 'full_name', 'full_name_flipped']],\n",
    "                                                    left_on='opponent_id', right_on='fighter_id', suffixes=('', '_y'))\n",
    "\n",
    "fight_details_tableau.rename(columns={'full_name' : 'opponent_name',\n",
    "                                      'full_name_flipped' : 'opponent_name_flipped'\n",
    "                                     }, inplace=True)\n",
    "\n",
    "# Import rankings snapshots\n",
    "with open('rankings_snapshots.pickle', 'rb') as read_file:\n",
    "    snapshots = pickle.load(read_file)\n",
    "\n",
    "# Convert date columns to datetime in rankings snapshots and fight detail tables, sort ascending\n",
    "fight_details_tableau['event_date'] = pd.to_datetime(fight_details_tableau['event_date'], format='%Y-%m-%d')\n",
    "fight_details_tableau = fight_details_tableau.sort_values('event_date')\n",
    "\n",
    "snapshots['date'] = pd.to_datetime(snapshots['date'], format='%m/%d/%Y')\n",
    "snapshots = snapshots.sort_values(['date', 'rank'])\n",
    "\n",
    "# Drop duplicates of event date and fighter name (keep highest ranking)\n",
    "snapshot_no_dups = snapshots.drop_duplicates(subset=['date', 'fighter'])\n",
    "\n",
    "# Replace fighter names to match rankings website\n",
    "name_replace = {'Aleksei Oleinik' : 'Alexey Oleynik',\n",
    "                'BJ Penn' : 'B.J. Penn',\n",
    "                'Benson Henderson' : 'Ben Henderson',\n",
    "                'C.B. Dollaway' : 'CB Dollaway',\n",
    "                'Constantinos Philippou' : 'Costas Philippou',\n",
    "                'Dooho Choi' : 'Doo Ho Choi',\n",
    "                'Georges St-Pierre' : 'Georges St. Pierre',\n",
    "                'JJ Aldrich' : 'J.J. Aldrich',\n",
    "                'Jacare Souza' : 'Ronaldo Souza',\n",
    "                'Jimy Hettes' : 'Jim Hettes',\n",
    "                'Joe Duffy' : 'Joseph Duffy',\n",
    "                'Jose Quinonez' : 'Jose Alberto Quinonez',\n",
    "                'Kai Kara-France' : 'Kai Kara France',\n",
    "                'Khalil Rountree Jr.' : 'Khalil Rountree',\n",
    "                'Luis Henrique' : 'Luis Henrique Barbosa de Oliveira',\n",
    "                'Manvel Gamburyan' : 'Manny Gamburyan',\n",
    "                'Matthew Riddle' : 'Matt Riddle',\n",
    "                'Mike Brown' : 'Mike Thomas Brown',\n",
    "                'Ovince Saint Preux' : 'Ovince St. Preux',\n",
    "                'Renato Moicano' : 'Renato Carneiro',\n",
    "                'Rob Emerson' : 'Robert Emerson',\n",
    "                'Robert Peralta' : 'Robbie Peralta',\n",
    "                'Rogerio Nogueira' : 'Antonio Rogerio Nogueira',\n",
    "                'Rony Jason' : 'Rony Mariano Bezerra',\n",
    "                'Serghei Spivac' : 'Sergey Spivak',\n",
    "                'SeungWoo Choi' : 'Seung Woo Choi',\n",
    "                'TJ Dillashaw' : 'T.J. Dillashaw',\n",
    "                'TJ Grant' : 'T.J. Grant',\n",
    "                'TJ Waldburger' : 'T.J. Waldburger',\n",
    "                'Khaos Williams' : 'Kalinn Williams'\n",
    "               }\n",
    "\n",
    "# Remap incorrect names using dictionary\n",
    "fight_details_tableau['opponent_name_clean'] = fight_details_tableau['opponent_name']\n",
    "fight_details_tableau['opponent_name_flipped_clean'] = fight_details_tableau['opponent_name_flipped']\n",
    "\n",
    "fight_details_tableau['opponent_name_clean'] = fight_details_tableau['opponent_name_clean'].replace(name_replace)\n",
    "fight_details_tableau['opponent_name_flipped_clean'] = fight_details_tableau['opponent_name_flipped_clean'].replace(name_replace)\n",
    "\n",
    "# Create clean columns for merging (remove apostrophes, all lowercase, strip blanks)\n",
    "def clean_column(df, col):\n",
    "    \"\"\"\n",
    "    Replace apostrophes with blanks, convert to lowercase, and strip any blanks.\n",
    "    \"\"\"\n",
    "    df[col] = df[col].replace({'\\'': ''}, regex=True)\n",
    "    df[col] = df[col].str.lower().str.strip()\n",
    "    \n",
    "clean_column(fight_details_tableau, 'opponent_name_clean')\n",
    "clean_column(fight_details_tableau, 'opponent_name_flipped_clean')\n",
    "clean_column(snapshot_no_dups, 'fighter')\n",
    "\n",
    "# Merge rankings data based on the latest snapshot (merge \"as of\")\n",
    "fight_details_tableau = pd.merge_asof(fight_details_tableau, snapshot_no_dups, left_on='event_date', right_on='date', left_by='opponent_name_clean',\n",
    "                                      right_by='fighter')\n",
    "\n",
    "fight_details_tableau = pd.merge_asof(fight_details_tableau, snapshot_no_dups, left_on='event_date', right_on='date', left_by='opponent_name_flipped_clean',\n",
    "                                      right_by='fighter')\n",
    "\n",
    "fight_details_tableau['opponent_rank'] = fight_details_tableau[['rank_x','rank_y']].min(axis=1)\n",
    "\n",
    "# Determine result for each fighter and fight combination (win/loss/draw)\n",
    "fight_details_tableau['result'] = np.where(fight_details_tableau['winner_id'].isin(['NC', 'Draw']), fight_details_tableau['winner_id'],\n",
    "                                           np.where(fight_details_tableau['winner_id']==fight_details_tableau['fighter_id'], 'Win', 'Loss')\n",
    "                                          )\n",
    "\n",
    "# Create bonus detail column considering whether the fighter won or loss the fight\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau['bonus'].str.split(', ')\n",
    "\n",
    "bonus_dict = {'winner' : {'belt' : 'Belt',\n",
    "                          'ko' : 'KO',\n",
    "                          'sub' : 'SUB',\n",
    "                          'fight' : 'FOTN',\n",
    "                          'perf' : 'POTN'\n",
    "                         },\n",
    "              'loser' : {'belt' : '',\n",
    "                         'ko' : '',\n",
    "                         'sub' : '',\n",
    "                         'fight' : 'FOTN',\n",
    "                         'perf' : ''\n",
    "                        }\n",
    "             }\n",
    "\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau.apply(lambda x: [] if x['bonus_detail']==None else \n",
    "                                                                    [bonus_dict['winner' if x['result']=='Win' else 'loser'][i] for i in x['bonus_detail']], axis=1)\n",
    "\n",
    "fight_details_tableau['bonus_detail'] = fight_details_tableau['bonus_detail'].str.join(', ').str.strip().str.strip(',')\n",
    "fight_details_tableau['bonus_detail'] = np.where(fight_details_tableau['bonus_detail']=='', None, fight_details_tableau['bonus_detail'])\n",
    "\n",
    "# Filter tableau table to only necessary columns\n",
    "tableau_fight_cols = ['fighter_id', 'fight_id', 'opponent_name', 'opponent_rank', 'weightclass', 'event_date', 'recency', \n",
    "                      'rds_sched', 'rd_ended', 'result', 'method', 'bonus_detail']\n",
    "fight_details_tableau = fight_details_tableau[tableau_fight_cols]\n",
    "fight_details_tableau = fight_details_tableau.merge(merged_metrics_by_fight, on=['fight_id', 'fighter_id'], how='left')\n",
    "\n",
    "### *Historical Rankings*\n",
    "\n",
    "# Clean snapshots and fighter_details columns for merging fighter_ids\n",
    "clean_column(snapshots, 'fighter')\n",
    "\n",
    "fighter_details_tableau['full_name_clean'] = fighter_details_tableau['full_name']\n",
    "fighter_details_tableau['full_name_clean'] = fighter_details_tableau['full_name_clean'].replace(name_replace)\n",
    "clean_column(fighter_details_tableau, 'full_name_clean')\n",
    "\n",
    "clean_column(fighter_details_tableau, 'full_name_flipped')\n",
    "\n",
    "# Merge fighter ids where possible\n",
    "snapshots = snapshots.merge(fighter_details_tableau[['full_name_flipped', 'fighter_id']], left_on='fighter', right_on='full_name_flipped', how='left')\n",
    "snapshots = snapshots.merge(fighter_details_tableau[['full_name_clean', 'fighter_id']], left_on='fighter', right_on='full_name_clean', how='left')\n",
    "\n",
    "snapshots['fighter_id'] = np.where(snapshots['fighter_id_x'].isnull(), snapshots['fighter_id_y'], snapshots['fighter_id_x'])\n",
    "\n",
    "# Filter columns for Tableau\n",
    "rankings_tableau = snapshots[['date', 'division', 'rank', 'fighter_id']]\n",
    "\n",
    "# Reset Tableau columns for fighter details table\n",
    "fighter_details_tableau = fighter_details_tableau[fighter_cols + ['top_cluster_all', 'top_cluster_past_10', 'top_cluster_past_5'] + ['full_name']]\n",
    "\n",
    "# Add a blank row for use in the fighter selection parameter in Tableau\n",
    "fighter_details_tableau.loc[fighter_details_tableau.shape[0]] = [None] * len(fighter_details_tableau.columns)\n",
    "fighter_details_tableau.iloc[-1, -1] = '(None Selected)'\n",
    "\n",
    "### *Upcoming Event*\n",
    "\n",
    "# Request upcoming events page\n",
    "page = requests.get('http://ufcstats.com/statistics/events/upcoming').text\n",
    "soup = BeautifulSoup(page, 'html5lib')\n",
    "\n",
    "# Request html for the next event only\n",
    "next_event = soup.find('table').find('a').get('href')\n",
    "\n",
    "page = requests.get(next_event).text\n",
    "soup = BeautifulSoup(page, 'html5lib')\n",
    "\n",
    "# Get fighter details for next event\n",
    "fighters = soup.find('table').find_all('a')\n",
    "\n",
    "matchups = []\n",
    "\n",
    "for i in range(0, len(fighters), 3):\n",
    "    fighter_1 = fighters[i].text.strip()\n",
    "    fighter_2 = fighters[i + 1].text.strip()\n",
    "    \n",
    "    matchups.append(fighter_1 + ' vs. ' + fighter_2)\n",
    "\n",
    "# Save matchups for next event to a dataframe\n",
    "tableau_matchups = pd.DataFrame({'Matchup' : matchups, 'Order' : range(len(matchups))})\n",
    "\n",
    "### *Save Tables to Excel*\n",
    "\n",
    "fighter_metrics_tableau.to_excel('tableau_fighter_metrics.xlsx', sheet_name='fighter_metrics')\n",
    "cluster_breakdown_tableau.to_excel('tableau_cluster_breakdowns.xlsx', sheet_name='clusters')\n",
    "fighter_details_tableau.to_excel('tableau_fighter_details.xlsx', sheet_name='fighter_details')\n",
    "fight_details_tableau.to_excel('tableau_fight_details.xlsx', sheet_name='fight_details')\n",
    "tableau_matchups.to_excel('tableau_matchups.xlsx', sheet_name='matchups', header=True)\n",
    "rankings_tableau.to_excel('tableau_rankings.xlsx', sheet_name='rankings', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
